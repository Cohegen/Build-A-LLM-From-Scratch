{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2d1n1846I161K58XVAIdb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Different categories of finetuning\n"
      ],
      "metadata": {
        "id": "Kd-bNUFdnk7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The most common ways of fine-tuning a language model are `instruction fine-tuning` and `classification fine-tuning`.\n",
        "* Instruction fine-tuning involves training a language model on a set of tsks using specific instructions to improve its ability to understand and execute tasks.\n",
        "* Classification fine-tuning is a concept whereby the model is trained to recognize a specific set of class labels."
      ],
      "metadata": {
        "id": "CZ8d8eIGnqP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Preparing the dataset"
      ],
      "metadata": {
        "id": "g4rNtqzootG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##downloading and unzipping the dataset\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_extract(url,zip_path,extracted_path,data_file_path):\n",
        "  if data_file_path.exists():\n",
        "    print(f\"{data_file_path},already exists. Skipping download\")\n",
        "    return\n",
        "\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    with open(zip_path,\"wb\") as out_file:\n",
        "      out_file.write(response.read())\n",
        "\n",
        "    with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
        "      zip_ref.extractall(extracted_path)\n",
        "\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path,data_file_path)\n",
        "    print(f\"File donwload and saved as {data_file_path}\")\n",
        "\n",
        "download_and_extract(url,zip_path,extracted_path,data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67z_zVNOo0dy",
        "outputId": "9a2b4490-bd67-475a-82eb-c5133830e4dd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv,already exists. Skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(data_file_path,sep=\"\\t\",header=None,names=[\"Label\",\"Text\"])\n",
        "df = pd.DataFrame(df)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "A0IB87Vmq-w5",
        "outputId": "25035d8c-9afe-4224-97e9-aa2c32020324"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59b5ed10-e53b-465a-8de5-1e3f8689fa6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59b5ed10-e53b-465a-8de5-1e3f8689fa6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59b5ed10-e53b-465a-8de5-1e3f8689fa6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59b5ed10-e53b-465a-8de5-1e3f8689fa6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dffb4466-454f-4227-9231-325285cfe0be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dffb4466-454f-4227-9231-325285cfe0be')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dffb4466-454f-4227-9231-325285cfe0be button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3f1cf388-6275-45cc-a1b3-9b82e30bf2e8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3f1cf388-6275-45cc-a1b3-9b82e30bf2e8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##examining class label distribution\n",
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTs0N6KcrO5D",
        "outputId": "39cc59c4-748d-4b8a-9e49-3920b0910695"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a balanced dataset\n",
        "def balanced_dataset(df):\n",
        "  num_spam = df[df[\"Label\"]== \"spam\"].shape[0]\n",
        "  ham_subset = df[df[\"Label\"]==\"ham\"].sample(num_spam,random_state=123)\n",
        "  balanced_df = pd.concat([ham_subset,df[df[\"Label\"] == \"spam\"]])\n",
        "  return balanced_df\n",
        "\n",
        "balanced_df = balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUNtnUtcrui9",
        "outputId": "f16864b1-0c4a-41fa-91c3-163ec48e91b7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##converting labels into integers\n",
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0,\"spam\":1})"
      ],
      "metadata": {
        "id": "yKhNZ1wtsfQ1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##splitting the dataset\n",
        "def random_split(df,train_frac,validation_frac):\n",
        "  df = df.sample(\n",
        "      frac=1,random_state=123\n",
        "  ).reset_index(drop=True)\n",
        "  train_end = int(len(df)* train_frac)\n",
        "  validation_end = train_end + int(len(df)*validation_frac)\n",
        "\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:validation_end]\n",
        "  test_df = df[validation_end:]\n",
        "\n",
        "  return train_df,validation_df,test_df\n",
        "\n",
        "train_df,validation_df,test_df= random_split(balanced_df,0.7,0.1)"
      ],
      "metadata": {
        "id": "oy9lTJ_DsxOj"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the dataset as CSV\n",
        "train_df.to_csv(\"train.csv\",index=None)\n",
        "validation_df.to_csv(\"validation.csv\",index=None)\n",
        "test_df.to_csv(\"test.csv\",index=None)"
      ],
      "metadata": {
        "id": "3_GHoF4qsIbY"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Creating dataLoaders\n"
      ],
      "metadata": {
        "id": "VNZHmA-wujDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50XomvRsu0rp",
        "outputId": "048ae306-596e-4cd0-e8e8-ca0db204aced"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "  def __init__(self,csv_file,tokenizer,max_length=None,pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    self.encoded_texts = [\n",
        "        tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "    ]\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "      self.encoded_texts = [\n",
        "          encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
        "      ]\n",
        "\n",
        "    self.encoded_texts = [\n",
        "        encoded_text + [pad_token_id]* (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts\n",
        "    ]\n",
        "\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    encoded = self.encoded_texts[index]\n",
        "    label = self.data.iloc[index][\"Label\"]\n",
        "    return (\n",
        "        torch.tensor(encoded),\n",
        "        torch.tensor(label)\n",
        "    )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def _longest_encoded_length(self):\n",
        "    max_length = 0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      encoded_length = len(encoded_text)\n",
        "      if encoded_length >max_length:\n",
        "        max_length = encoded_length\n",
        "    return max_length"
      ],
      "metadata": {
        "id": "SOesQIziZxWR"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The class above loads data from the CSV files we created earlier, tokenizes the text using the GPT-2 tokenizer, and allows us to pad or truncate the sequneces to a uniform length determined by either the longest sequence or a predefined maximum length."
      ],
      "metadata": {
        "id": "2UNKh71EcTuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "Cbcen64tcxqZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht-ujX3gc72K",
        "outputId": "3fa1c16c-cea3-4542-b4d8-a5612eeb9bd0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Code shows 10,meaning the longest sequence contains no more than 10 tokens.\n",
        "* Next we pad the validation and test samples exceeding the length of the longest training example."
      ],
      "metadata": {
        "id": "FFIzZ2tAdF2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "Dfd6b138dhEk"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##creating a pytorch dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers =0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "id": "__dB5I3FeHVs"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##iterative over training loader\n",
        "for input_batch, target_batch in train_loader:\n",
        "  pass\n",
        "print(\"Input batch dimensions:\",input_batch.shape)\n",
        "print(\"Label batch dimensions:\",target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QMLMt3UfEOm",
        "outputId": "e5a2816a-e413-4725-aa7c-5174ba70f2b6"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##print total number of batches in each dataset\n",
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln8TpBxEgbcg",
        "outputId": "b75107b4-e3a8-42bd-bdff-868e402d3a8a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Initializing a model with pretrained weights"
      ],
      "metadata": {
        "id": "HKNfiWnwhCgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code we need for the model to work"
      ],
      "metadata": {
        "id": "C11b6q05i75B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##reusing the multiheadattention class\n",
        "import torch.nn as nn\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.w_query = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.w_key = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.w_value = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out,d_out) # Corrected d_in to d_out\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    b,num_tokens,d_in = x.shape\n",
        "    keys = self.w_key(x)\n",
        "    values = self.w_value(x)\n",
        "    queries = self.w_query(x)\n",
        "    ##splitting matrix by adding a num_heads and head_dim dimensions\n",
        "    keys= keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    values = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "\n",
        "    #tranpsoing from shape (b,num_tokens,num_heads,head_dim) to (b,num_heads,num_tokens,head_dim)\n",
        "    keys = keys.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "    queries = queries.transpose(1,2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2,3) # Fixed typo tranpose -> transpose\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens].unsqueeze(0).unsqueeze(0) # Added unsqueeze for broadcasting\n",
        "\n",
        "    attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores /keys.shape[-1]**0.5,dim=-1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec_per_head = (attn_weights @ values).transpose(1,2) # Fixed typo tranpose -> transpose and renamed variable\n",
        "\n",
        "    context_vec = context_vec_per_head.contiguous().view( # Used corrected variable name\n",
        "        b,num_tokens,self.d_out\n",
        "    )\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec\n"
      ],
      "metadata": {
        "id": "QRQ3lPKjjBQw"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## layernorm class\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean = x.mean(dim=-1,keepdim=True)\n",
        "    var = x.var(dim=-1,keepdim=True)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "TvOtC0sYjHZ1"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi)) * (x + 0.044715 * torch.pow(x,3))\n",
        "    ))"
      ],
      "metadata": {
        "id": "rTQZyqfAjQQm"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "PU1uvze8jWeJ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_size\"],\n",
        "        num_heads = cfg[\"n_heads\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        qkv_bias = cfg[\"qkv_bias\"]\n",
        "\n",
        "    )\n",
        "    self.ffn = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x) # Fixed typo: dropout_shortcut -> drop_shortcut\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ffn(x) # Fixed typo: ff -> ffn\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x"
      ],
      "metadata": {
        "id": "lQSz5qTXjgTK"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_size\"],cfg[\"emb_dim\"]) # Changed context_length to context_size\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "\n",
        "    )\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"],bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self,in_idx):\n",
        "    batch_size,seq_len = in_idx.shape\n",
        "    tok_embeds= self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "        torch.arange(seq_len,device=in_idx.device)\n",
        "    )\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x) # Corrected dropout application\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "SZ3C0Irgjhcs"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mmOsBVdRjCwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Evert effort moves\"\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\":50257,\n",
        "    \"context_size\":1024,\n",
        "    \"drop_rate\":0.0,\n",
        "    \"qkv_bias\":True\n",
        "}\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "HoRqpg0IhKmP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/\"\n",
        "    \"LLMs-from-scratch/main/ch05/\"\n",
        "    \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLOBzYdhkY2J",
        "outputId": "c434dbf1-fff9-4a76-d620-c3563e1f7044"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x78bdfabe3f20>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left,right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(f\"Shape mismatch. Left: {left.shape},\" f\"Right: {right.shape}\")\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "CSM8MTvdlEMq"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt,params):\n",
        "  gpt.pos_emb.weight = assign(\n",
        "      gpt.pos_emb.weight,\n",
        "      params['wpe']\n",
        "  )\n",
        "  gpt.tok_emb.weight = assign(\n",
        "      gpt.tok_emb.weight,\n",
        "      params['wte']\n",
        "  )\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    q_w, k_w, v_w = np.split(\n",
        "    (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.w_query.weight = assign(\n",
        "        gpt.trf_blocks[b].att.w_query.weight, q_w.T\n",
        "    )\n",
        "    gpt.trf_blocks[b].att.w_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.w_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.w_value.weight = assign(\n",
        "           gpt.trf_blocks[b].att.w_value.weight, v_w.T)\n",
        "    q_b, k_b, v_b = np.split(\n",
        "         (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.w_query.bias = assign(\n",
        "         gpt.trf_blocks[b].att.w_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.w_key.bias = assign(\n",
        "          gpt.trf_blocks[b].att.w_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.w_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.w_value.bias, v_b)\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "           gpt.trf_blocks[b].att.out_proj.weight,\n",
        "           params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "        gpt.trf_blocks[b].att.out_proj.bias,\n",
        "          params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ffn.layers[0].weight = assign(\n",
        "           gpt.trf_blocks[b].ffn.layers[0].weight,\n",
        "           params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ffn.layers[0].bias = assign(\n",
        "              gpt.trf_blocks[b].ffn.layers[0].bias,\n",
        "              params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ffn.layers[2].weight = assign(\n",
        "             gpt.trf_blocks[b].ffn.layers[2].weight,\n",
        "             params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ffn.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ffn.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "           gpt.trf_blocks[b].norm1.scale,\n",
        "           params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "             gpt.trf_blocks[b].norm1.shift,\n",
        "             params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm2.scale = assign(\n",
        "         gpt.trf_blocks[b].norm2.scale,\n",
        "         params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm2.shift = assign(\n",
        "    gpt.trf_blocks[b].norm2.shift,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
      ],
      "metadata": {
        "id": "y8bI_Rxpk7Sc"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:,-1,:]\n",
        "    if top_k is not None:\n",
        "      top_logits, _ = torch.topk(logits,top_k)\n",
        "      min_val = top_logits[:,-1]\n",
        "      logits = torch.where(\n",
        "          logits < min_val,\n",
        "          torch.tensor(float('-inf')).to(logits.device),\n",
        "          logits\n",
        "      )\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits,dim=-1)\n",
        "      idx_next = torch.multinomial(probs,num_samples=1)\n",
        "    else:\n",
        "      idx_next =torch.argmax(logits,dim=-1,keepdim=True)\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "    idx = torch.cat((idx,idx_next),dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "9e8kM4S2nonH"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)# unsqueeze adds the batch dimension\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0) #remove batch dimension\n",
        "  return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "EXJqAyzQn8t2"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "# Merge BASE_CONFIG with model-specific configurations\n",
        "cfg = {**BASE_CONFIG, **model_configs[CHOOSE_MODEL]}\n",
        "model = GPTModel(cfg)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq9KPkO0kapb",
        "outputId": "e472ad6a-71c8-41f1-e5da-0a3d4c8d80a1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Every effort moves\"\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx = text_to_token_ids(text1,tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_size\"]\n",
        "\n",
        ")\n",
        "print(token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVh74pRSoVxA",
        "outputId": "dee47c68-0b2b-46ab-801a-2561443eb367"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves forward, but it's not enough.\n",
            "\n",
            "\"I'm not going\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx = text_to_token_ids(text2,tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG['context_size']\n",
        "\n",
        ")\n",
        "print(token_ids_to_text(token_ids,tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8_5GG0hiV_p",
        "outputId": "538d1f9a-8f0c-4141-d347-b00baeae780c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Adding a classification head\n"
      ],
      "metadata": {
        "id": "Bsd87HkHpdeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##adding a classification layer\n",
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(\n",
        "    in_features=cfg['emb_dim'],\n",
        "    out_features=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "zTkRO2wwppa2"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making the output layer,final layernorm and transformer blocl trainable\n",
        "for param in model.trf_blocks[-1].parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "H9iDMP5RqeOC"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##example\n",
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\",inputs)\n",
        "print(\"Inputs shape:\",inputs.shape)"
      ],
      "metadata": {
        "id": "FxEaQfLzrDDr",
        "outputId": "707bb551-e146-40b6-ab8d-e570c43c6bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(inputs)\n",
        "print(\"Outputs:\\n\",outputs)\n",
        "print(\"Outputs dimensions:\",outputs.shape)"
      ],
      "metadata": {
        "id": "EXvsKcwZriX2",
        "outputId": "bb843462-fdf3-488f-b1e5-c000ba78af72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5883,  0.9920],\n",
            "         [-3.7208,  7.4510],\n",
            "         [-2.2642,  6.6005],\n",
            "         [-3.5965,  3.9889]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "id": "gpvuTbPosAas",
        "outputId": "3fadf4f2-ffc5-441e-c830-056a7dec45ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5965,  3.9889]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Calculating the classification loss and accuracy\n"
      ],
      "metadata": {
        "id": "mwu-j5neK2nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\",outputs[:,-1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Iw3J7bLHC3",
        "outputId": "9728188c-f7d5-4420-9695-3ca1531adcf9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5965,  3.9889]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##obtaining class labels\n",
        "probs = torch.softmax(outputs[:,-1,:],dim=-1)\n",
        "label = torch.argmax(probs)\n",
        "print(\"Class label:\",label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XLsKgkOLQW1",
        "outputId": "596a4f3e-e8c4-49ec-b6d4-b433c126b8ee"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Code returns 1, meaning the model predicts that the input text is 'spam'.\n"
      ],
      "metadata": {
        "id": "O3VQ89M-Lh9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[:,-1,:]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\",label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uox8mGl9LqsR",
        "outputId": "23933c8d-dfe6-410a-d65f-afcafddf81a6"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculating classification accuracy\n",
        "def accuray_loader(data_loader,model,device,num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions,num_examples= 0,0\n",
        "\n",
        "  if num_batches is None:\n",
        "    num_batches_to_process = len(data_loader)\n",
        "  else:\n",
        "    num_batches_to_process = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i >= num_batches_to_process:\n",
        "      break # Stop after processing the desired number of batches\n",
        "\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_batch)[:,-1,:]\n",
        "    predicted_labels = torch.argmax(logits,dim=-1)\n",
        "    correct_predictions += (\n",
        "        (predicted_labels == target_batch).sum().item()\n",
        "    )\n",
        "    num_examples += target_batch.size(0) # Increment by batch size\n",
        "\n",
        "  if num_examples == 0: # Avoid division by zero if no examples were processed\n",
        "      return 0.0\n",
        "  return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "c3jbeouEL3V5"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_accuracy = accuray_loader(\n",
        "    train_loader,model,device,num_batches=10\n",
        ")\n",
        "val_accuracy = accuray_loader(\n",
        "    val_loader,model,device,num_batches=10\n",
        ")\n",
        "test_accuracy = accuray_loader(\n",
        "    test_loader,model,device,num_batches=10\n",
        ")\n",
        "print(f\"Training accuracy: {train_accuracy*100:.4f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.4f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWzXbGBvOoek",
        "outputId": "047a8c92-6133-4d6a-a4af-7b6a7a011727"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.2500%\n",
            "Validation accuracy: 45.0000%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## minimizing loss using cross entropy loss since classification loss is\n",
        "## not  differentiable\n",
        "def loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)[:,-1,:] #logits of last output token\n",
        "\n",
        "  loss = torch.nn.functional.cross_entropy(logits,target_batch)\n",
        "  return loss\n",
        ""
      ],
      "metadata": {
        "id": "ampjuxqfSYW-"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##calculating the classification loss\n",
        "def loss_loader(data_loader,model,device,num_batches=None):\n",
        "  total_loss =0\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches,len(data_loader))\n",
        "  for i, (input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "Zq0xjpv-TFtL"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##computing the intial loss for each data set\n",
        "with torch.no_grad():\n",
        "  train_loss = loss_loader(\n",
        "      train_loader,model,device,num_batches=5\n",
        "  )\n",
        "  val_loss = loss_loader(val_loader,model,device,num_batches=5)\n",
        "  test_loss = loss_loader(test_loader,model,device,num_batches=5)\n",
        "\n",
        "  print(f\"Training loss: {train_loss:.3f}\")\n",
        "  print(f\"Validation loss: {val_loss:.3f}\")\n",
        "  print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgpL1AoKUS-v",
        "outputId": "b2f7c5fb-0125-4a94-e9bc-53173afb59b9"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.445\n",
            "Validation loss: 2.575\n",
            "Test loss: 2.314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Fine-tuning the model on supervised data"
      ],
      "metadata": {
        "id": "oUekNV-DWAqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here we must define and use the training function to fine tune the pretrained LLM and improve its spam classification accuracy."
      ],
      "metadata": {
        "id": "4IEEhjSTWPXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter):\n",
        "  train_losses,val_losses,train_acc,val_acc = [],[],[],[]\n",
        "  examples_seen, global_step = 0, -1\n",
        "\n",
        "  ##main training loop\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for input_batch,target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      loss.backward() #calculating loss gradients\n",
        "      optimizer.step() #updating model weights using loss gradients\n",
        "      examples_seen += input_batch.shape[0]\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss,val_loss = evaluate_model(\n",
        "            model,train_loader,val_loader,device,eval_iter\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch{epoch+1} Step{global_step:06d}\" f\"Train loss {train_loss:.3f}, \" f\"Val_ loss {val_loss:.3f}\")\n",
        "\n",
        "  train_accuracy = accuray_loader(\n",
        "      train_loader,model,device,num_batches=eval_iter\n",
        "  )\n",
        "  val_accuracy = accuray_loader(\n",
        "      val_loader,model,device,num_batches=eval_iter\n",
        "  )\n",
        "  print(f\"Training accuracy: {train_accuracy*100:.2f} % | \", end=\"\")\n",
        "  print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "  train_acc.append(train_accuracy)\n",
        "  val_acc.append(val_accuracy)\n",
        "  return train_losses,val_losses,train_acc,val_acc,examples_seen"
      ],
      "metadata": {
        "id": "_8z2wr27Wdxj"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = loss_loader(\n",
        "        train_loader,model,device,num_batches=eval_iter\n",
        "    )\n",
        "\n",
        "    val_loss = loss_loader(\n",
        "        val_loader,model,device,num_batches=eval_iter\n",
        "    )\n",
        "    model.train()\n",
        "    return train_loss,val_loss"
      ],
      "metadata": {
        "id": "NHG0JCc2ZRsZ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=5e-5,weight_decay=0.1)\n",
        "num_epochs = 5\n",
        "\n",
        "train_losses,val_losses,train_acc,val_acc,examples_seen = (\n",
        "    train_classifier(\n",
        "        model,train_loader,val_loader,optimizer,device,\n",
        "        num_epochs=num_epochs,eval_freq=50,eval_iter=5\n",
        "    )\n",
        "\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time = (end_time-start_time) / 60\n",
        "print(f\"Training completed in {execution_time:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86SRierKaGkV",
        "outputId": "5bfe89a8-185d-447f-e622-9058a2df9328"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1 Step000000Train loss 2.917, Val_ loss 2.626\n",
            "Epoch1 Step000050Train loss 0.306, Val_ loss 0.194\n",
            "Epoch1 Step000100Train loss 0.120, Val_ loss 0.430\n",
            "Epoch2 Step000150Train loss 0.060, Val_ loss 0.177\n",
            "Epoch2 Step000200Train loss 0.087, Val_ loss 0.045\n",
            "Epoch2 Step000250Train loss 0.019, Val_ loss 0.056\n",
            "Epoch3 Step000300Train loss 0.127, Val_ loss 0.293\n",
            "Epoch3 Step000350Train loss 0.013, Val_ loss 0.122\n",
            "Epoch4 Step000400Train loss 0.029, Val_ loss 0.174\n",
            "Epoch4 Step000450Train loss 0.000, Val_ loss 0.076\n",
            "Epoch4 Step000500Train loss 0.000, Val_ loss 0.023\n",
            "Epoch5 Step000550Train loss 0.000, Val_ loss 0.025\n",
            "Epoch5 Step000600Train loss 0.000, Val_ loss 0.081\n",
            "Training accuracy: 100.00 % | Validation accuracy: 97.50%\n",
            "Training completed in 2.48 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting classification loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen,examples_seen,train_values,val_values,label=\"loss\"):\n",
        "  fig,ax1 = plt.subplots(figsize=(5,3))\n",
        "  ax1.plot(epochs_seen,train_values,label=f\"Training {label}\")\n",
        "  ax1.plot(epochs_seen,val_values,linestyle=\"-.\",label=f\"Validation {label}\")\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(label.capitalize())\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(examples_seen,train_values,alpha=0)\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0,examples_seen,len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor,examples_seen_tensor,train_losses,val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "bweXWWDbb0Ki",
        "outputId": "2dd1e9bc-e726-47cd-e7bd-ab7405c2b9be"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see from the plot above, based on the sharp downward slope, the model is learning well from the training data, and there is little to o indicationof overfiiting i.e there is no noticeable gap between the training and validation set losses."
      ],
      "metadata": {
        "id": "j4qIss_wdltb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = accuray_loader(\n",
        "    train_loader,model,device\n",
        ")\n",
        "val_accuracy = accuray_loader(\n",
        "    val_loader,model,device\n",
        ")\n",
        "test_accuracy = accuray_loader(\n",
        "    test_loader,model,device\n",
        ")\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdF1B2TmgE8L",
        "outputId": "a410e4e7-f5df-4eee-8e9f-d2b5d0385c9e"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 98.66%\n",
            "Test accuracy: 97.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.8 Using the LLM as a spam classifier"
      ],
      "metadata": {
        "id": "KJwq0BsIjCo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text,model,tokenizer,device,max_length=None,pad_token_id=50256):\n",
        "  model.eval()\n",
        "\n",
        "  input_ids = tokenizer.encode(text)\n",
        "  supported_context_length = model.pos_emb.weight.shape[1]\n",
        "\n",
        "  input_ids = input_ids[:min(max_length,supported_context_length)]\n",
        "  input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "  input_tensor = torch.tensor(input_ids,device=device).unsqueeze(0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)[:,-1,:]\n",
        "  predicted_label =torch.argmax(logits,dim=-1).item()\n",
        "\n",
        "  return \"spam\" if predicted_label == 1 else \"not spam\""
      ],
      "metadata": {
        "id": "qw8F-aBvjHKO"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "     \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "print(classify_review(text_1,model,tokenizer,device,max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5h0Tp8MktLt",
        "outputId": "bc00bdb9-5f89-4934-e397-35073058656d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "     \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "print(classify_review(text_2,model,tokenizer,device,max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJbOUPWrlO6s",
        "outputId": "2cbfb360-21f7-4088-b2ed-c496eb0f9b41"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##saving the model\n",
        "torch.save(model.state_dict(),\"review_classifier.pth\")\n"
      ],
      "metadata": {
        "id": "hoHOVBjBlheM"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\",map_location=device)\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "bYONlPyzlts5",
        "outputId": "a5556445-07a8-4ecb-aab9-16e3482c499a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    }
  ]
}