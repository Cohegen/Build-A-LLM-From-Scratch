{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s_LNYZcCJP0a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GKpBetmZJ7VL"
      },
      "outputs": [],
      "source": [
        "##reusing the multiheadattention class\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.w_query = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.w_key = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.w_value = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out,d_out) # Corrected d_in to d_out\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    b,num_tokens,d_in = x.shape\n",
        "    keys = self.w_key(x)\n",
        "    values = self.w_value(x)\n",
        "    queries = self.w_query(x)\n",
        "    ##splitting matrix by adding a num_heads and head_dim dimensions\n",
        "    keys= keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    values = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "\n",
        "    #tranpsoing from shape (b,num_tokens,num_heads,head_dim) to (b,num_heads,num_tokens,head_dim)\n",
        "    keys = keys.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "    queries = queries.transpose(1,2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2,3) # Fixed typo tranpose -> transpose\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens].unsqueeze(0).unsqueeze(0) # Added unsqueeze for broadcasting\n",
        "\n",
        "    attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores /keys.shape[-1]**0.5,dim=-1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec_per_head = (attn_weights @ values).transpose(1,2) # Fixed typo tranpose -> transpose and renamed variable\n",
        "\n",
        "    context_vec = context_vec_per_head.contiguous().view( # Used corrected variable name\n",
        "        b,num_tokens,self.d_out\n",
        "    )\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nA-cSnb5KzzA"
      },
      "outputs": [],
      "source": [
        "## layernorm class\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean = x.mean(dim=-1,keepdim=True)\n",
        "    var = x.var(dim=-1,keepdim=True)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SPKQ07wOKuV8"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi)) * (x + 0.044715 * torch.pow(x,3))\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CD-DdgYIKqdz"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7i1J0EuMKhPd"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_size\"],\n",
        "        num_heads = cfg[\"n_heads\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        qkv_bias = cfg[\"qkv_bias\"]\n",
        "\n",
        "    )\n",
        "    self.ffn = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x) # Fixed typo: dropout_shortcut -> drop_shortcut\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ffn(x) # Fixed typo: ff -> ffn\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dWG0sqSRKa8U"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_size\"],cfg[\"emb_dim\"]) # Changed context_length to context_size\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "\n",
        "    )\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"],bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self,in_idx):\n",
        "    batch_size,seq_len = in_idx.shape\n",
        "    tok_embeds= self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "        torch.arange(seq_len,device=in_idx.device)\n",
        "    )\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x) # Corrected dropout application\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgvm52_9LEJP",
        "outputId": "aa369928-eb24-47de-b30a-0617cbba1cfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#from IPython.utils.process import get_output_error_code\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\":50257,\n",
        "    \"context_size\":256,\n",
        "    \"emb_dim\":768,\n",
        "    \"n_heads\":12,\n",
        "    \"n_layers\":12,\n",
        "    \"drop_rate\":0.1,\n",
        "    \"qkv_bias\":False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAUGgOdEMNKD"
      },
      "source": [
        "* Here we have made some few adjustment to the `GPT_CONFIG_124M` dictionary by reducing the context size to 256 tokens.\n",
        "* This modification reduces the computatioal demands of training the model, making it possible to carry out the training on a standard laptop cmputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jN9zmSnnM6W2"
      },
      "outputs": [],
      "source": [
        "def generate_text(model,idx,max_new_tokens,context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    # Crop idx to the last context_size tokens if it's longer\n",
        "    idx_cond = idx[:,  -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:,-1,:]\n",
        "    probs = torch.softmax(logits,dim=-1)\n",
        "    idx_next = torch.argmax(probs,dim=-1,keepdim=True)\n",
        "    idx = torch.cat((idx,idx_next),dim=1)\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ssZhjQpMrqr",
        "outputId": "30dfaea0-9ecc-41b2-fdd3-22ec00d8a6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "##implementing text generation process\n",
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)# unsqueeze adds the batch dimension\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0) #remove batch dimension\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context,tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_size\"]\n",
        ")\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpRLhsHdPJIK"
      },
      "source": [
        "* As we can see the model isn't yet producing coherent text because it hasn't undergone training.\n",
        "* To define what makes text 'coherent' or 'high quality' we have to implement a numerical method to evaluate the generated content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaXOGNRPPi6T"
      },
      "source": [
        "## 1.2  Calculating the text generation loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Y9EBmgP0DZ"
      },
      "source": [
        "* Consider these two input examples, which have already been mapped to token IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9AMmGbJLP8GB"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor(\n",
        "    [\n",
        "        [16833,3626,6100], #every effort moves\n",
        "        [40,1107,588] # I really like\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLXkgWXQPR4"
      },
      "source": [
        "* Matching these inpts, the targets contain token IDs we want the model to produce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yf15rIQpQYJL"
      },
      "outputs": [],
      "source": [
        "targets = torch.tensor([\n",
        "    [3626,6100,345],#every effort moves you\n",
        "    [1107,588,11311]#really like chocolate\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPhXu7hmQs3A"
      },
      "source": [
        "* Note that these targets are inputs but shifted one position forward. This shifting strategy is crucial for teaching the model to predict the next token in a sequence.\n",
        "* Next we feedthe inputs into the model to calculate logits vectors for the two input examples. The we apply the `softmax` function to transform these logits into probability scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0E6KUARRPo-",
        "outputId": "005adb8d-e692-4e33-80de-9b5d5e7b9bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "probs = torch.softmax(logits,dim=-1)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTRqCRH3Rm9r",
        "outputId": "df2e0b8e-4976-498e-e381-18f91c838a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "##applying the argmax function to the probability scores to obtain the correspoding token IDs\n",
        "token_ids = torch.argmax(probs,dim=-1,keepdim=True)\n",
        "print(\"Token IDs:\\n\",token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZqVYEUTSKia"
      },
      "source": [
        "* Given that we have two input batches, each containing three tokens, applying `argmax` function to the probability scores yields two set of outputs, each with three predicted token Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Dmi7TGSqif",
        "outputId": "21d9c78e-df20-4e05-db19-dc6353209830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target batch1: effort moves you\n",
            "Outputs batch1: Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "##converting the token IDs back into text\n",
        "print(f\"Target batch1:{token_ids_to_text(targets[0],tokenizer)}\")\n",
        "print(f\"Outputs batch1:\"f\"{token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E1cE0-BTpE9"
      },
      "source": [
        "* As we can see the model produces random text that is different from the target text because it has not been trained yet.\n",
        "* Model training aims to increase the softmax probability in the index postions corresponding to the correct target token Ids.\n",
        "* This softmax probability is also used in evaluation metric we will implement next to numerically access the model's generated outputs: higher probability in the correct positions, the better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdepar6rUspY",
        "outputId": "32e7c65a-309a-4ea6-85b8-d3ce30355a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4514e-05, 3.1054e-05, 1.1567e-05])\n",
            "Text 2:  tensor([1.0343e-05, 5.6737e-05, 4.7620e-06])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probs1 = probs[text_idx,[0,1,2],targets[text_idx]]\n",
        "print(\"Text 1:\",target_probs1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probs2 = probs[text_idx,[0,1,2],targets[text_idx]]\n",
        "print(\"Text 2: \",target_probs2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffUd2NVEVudy"
      },
      "source": [
        "* The goal of training an LLM is to maximize relative likelihood of the current token, which involves increasing its probability relative to other tokens.\n",
        "* This way, we ensure the LLM consistently picks the target token i.e the next word in the sentence as the next tokem it generates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmsYrII2YexF",
        "outputId": "4d0c1939-b6d7-4b23-8c9f-88f9c782d262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5045, -10.3798, -11.3674, -11.4792,  -9.7771, -12.2549])\n"
          ]
        }
      ],
      "source": [
        "##calculating probability scores of the two example batches\n",
        "log_probs =torch.log(torch.cat((target_probs1,target_probs2)))\n",
        "print(log_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnEVgEgVY31j"
      },
      "source": [
        "* Working with logarithms of the probabilities scores is more managable in mathematical optimization than handling the scores directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYXLEG1ZZLsu",
        "outputId": "f8b11931-5dbb-4360-f83f-b5d3b20efcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.7938)\n"
          ]
        }
      ],
      "source": [
        "##combining the log probabilities into  single score by computing the averagr\n",
        "avg_log_probs = torch.mean(log_probs)\n",
        "print(avg_log_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU5NL63JZhd0"
      },
      "source": [
        "* The goal is to get the average log probability as close to 0 as possilbe by updating the model's weights as part of the training process.\n",
        "* However, in deep learning, the common practice isn't to push the average log probability up to 0 but rather to bring the negative average log probability to 0.\n",
        "* The negative average log probability is simply the average log probability multiplied by -1 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Niy_Voawj-",
        "outputId": "bcb0fa5f-6381-4e21-ad40-2e34b0585ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7938)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probs = avg_log_probs *-1\n",
        "print(neg_avg_log_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMgt3mJpa9xT",
        "outputId": "a07e462c-5d52-4fed-b823-c4c621dc1b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape:  torch.Size([2, 3, 50257])\n",
            "Target shape:  torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "#recalling shape of the logits and target tensors\n",
        "print(\"Logits shape: \",logits.shape) #dim=batch_size,num_tokens,vocab_size\n",
        "print(\"Target shape: \",targets.shape)#batch_size and num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buwOolK_bsAw",
        "outputId": "4d563d58-e0a2-4292-cc04-988c16a3d664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits:  torch.Size([6, 50257])\n",
            "Flattened targets:  torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "##flattening tensors by combining them over the batch dimension\n",
        "logits_flat = logits.flatten(0,1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits: \",logits_flat.shape)\n",
        "print(\"Flattened targets: \",targets_flat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7qGZkEBcvxp"
      },
      "source": [
        "* Previously, we applied the softmax function, selected the probability scores corresponding to the target IDs, and computed the negative average log probabilites.\n",
        "* Pytorch's `cross_entropy` function will take care of the these steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfSAl1LAcP2t",
        "outputId": "23d67860-8951-4075-ff51-7c89b9a2271c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7938)\n"
          ]
        }
      ],
      "source": [
        "loss= torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOhXHcoXclcb"
      },
      "source": [
        "* The above resulting loss is the same that we obtained previously when applying the individual steps manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlgoSnbLdUzD"
      },
      "source": [
        "## 1.3 Calculating the trainig and validation set losses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy1fJzqfdcwd"
      },
      "source": [
        "* We must first prepare the training and validation datasets that we will use to train the LLM.\n",
        "* To compute loss, we use a very samll text dataset, the \"Notes from the underground\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9WpObyteHVP",
        "outputId": "2393ab7c-a485-4579-ca7b-29e090d81bee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pg600.txt', <http.client.HTTPMessage at 0x7a9d137902c0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import urllib.request\n",
        "url = \"https://www.gutenberg.org/cache/epub/600/pg600.txt\"\n",
        "input_file =\"pg600.txt\"\n",
        "urllib.request.urlretrieve(url, input_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iAmVAuYueetU"
      },
      "outputs": [],
      "source": [
        "with open(input_file,'r',encoding='utf-8') as f:\n",
        "  text_data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-mdOEm5epz3",
        "outputId": "9a30d35c-fb1b-46f3-d2a6-f32be889ca4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters:  259118\n",
            "Tokens: 67308\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters: \",total_characters)\n",
        "print(\"Tokens:\",total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9DFMXu2FfQsP"
      },
      "outputs": [],
      "source": [
        "##diving data into training and validation set\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio*len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buXyzObpfwwt"
      },
      "source": [
        "* Using the `train_data` and `val_data` subsets, we can now create the respective dataloader reusing the `create_dataloader_v1` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TNuw7nwLiYcD"
      },
      "outputs": [],
      "source": [
        "## creating a dataset for batched inputs and targets\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)##tokenizes text\n",
        "\n",
        "    for i in range(0,len(token_ids) - max_length,stride):#using sliding window to chuk the book into overlapping sequences of max_length\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kHZLJ1aif_xd"
      },
      "outputs": [],
      "source": [
        "## creating a dataloader to generate batches with input-with pairs\n",
        "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "  return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Oc14ZANae1NO"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_size\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_size\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_size\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_size\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ljeRL2kihoP",
        "outputId": "8b2b02d1-8251-4ef5-fc93-3d8c8132c0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader\")\n",
        "for x,y in train_loader:\n",
        "  print(x.shape,y.shape)\n",
        "print(\"\\nValidation loader:\")\n",
        "for x,y in val_loader:\n",
        "  print(x.shape,y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5WhNMjN0i7sw"
      },
      "outputs": [],
      "source": [
        "##implementing a utility function to calculate the cross entropy loss\n",
        "## of a given batch returned via the training and validation loader\n",
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(\n",
        "      logits.flatten(0,1),target_batch.flatten()\n",
        "  )\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZDgKO6aWjqr-"
      },
      "outputs": [],
      "source": [
        "##implementing a function to compute the training and validation loss\n",
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "  total_loss = 0\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "\n",
        "  # Determine the actual number of batches to process\n",
        "  if num_batches is None:\n",
        "    actual_num_batches = len(data_loader)\n",
        "  else:\n",
        "    actual_num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i < actual_num_batches:\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  # Avoid division by zero if actual_num_batches is 0\n",
        "  if actual_num_batches == 0:\n",
        "    return float(\"nan\")\n",
        "  return total_loss / actual_num_batches ##averaging loss over all batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w04IVeiomF2X",
        "outputId": "2077820a-3002-422a-d2c8-e557d2c4fe43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.979752308180352\n",
            "Validation loss: 10.972686608632406\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader,model,device)\n",
        "  val_loss = calc_loss_loader(val_loader,model,device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\",val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9KQp8INnrSY"
      },
      "source": [
        "* The loss values are relatively high because the model has not yet been trainied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIh4sbQmn5T8"
      },
      "source": [
        "## 1.4 Training the LLM to generate human like text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mpxhSebboG-U"
      },
      "outputs": [],
      "source": [
        "def train_model(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
        "  train_losses,val_losses,track_tokens_seen = [], [], []\n",
        "  tokens_seen,global_step = 0, -1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch,target_batch in train_loader:\n",
        "      optimizer.zero_grad() #rest loss gradients from previous batch iterations\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss,val_loss = evaluate_model(\n",
        "            model,train_loader,val_loader,eval_iter\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(\n",
        "            f\"Ep {epoch+1} (Step {global_step:06d}):\"\n",
        "            f\"Train Loss {train_loss:.3f},\"\n",
        "            f\"Val loss {val_loss:.2f}\"\n",
        "        )\n",
        "    generate(\n",
        "       model,tokenizer,device,start_context\n",
        "   )\n",
        "  return train_losses,val_losses,track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6pCPHeTeq_Ju"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,train_loader,val_loader,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(\n",
        "        train_loader,model,device,num_batches=eval_iter\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "        val_loader,model,device,num_batches=eval_iter\n",
        "    )\n",
        "  model.train()\n",
        "  return train_loss,val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iPZ_nSYcrEjk"
      },
      "outputs": [],
      "source": [
        "def generate(model,tokenizer,device,start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text(\n",
        "        model=model,\n",
        "        idx=encoded,\n",
        "        max_new_tokens=50,\n",
        "        context_size=context_size\n",
        "    )\n",
        "  decoded_text =token_ids_to_text(token_ids,tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\",\" \"))\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuUQTyx-jayV",
        "outputId": "a7be9685-7022-487f-d1c3-b7ed0b3de0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000):Train Loss 9.905,Val loss 9.86\n",
            "Ep 1 (Step 000005):Train Loss 8.366,Val loss 8.42\n",
            "Ep 1 (Step 000010):Train Loss 7.244,Val loss 7.64\n",
            "Ep 1 (Step 000015):Train Loss 6.927,Val loss 7.39\n",
            "Ep 1 (Step 000020):Train Loss 6.880,Val loss 7.43\n",
            "Ep 1 (Step 000025):Train Loss 6.651,Val loss 7.41\n",
            "Ep 1 (Step 000030):Train Loss 6.837,Val loss 7.35\n",
            "Ep 1 (Step 000035):Train Loss 6.775,Val loss 7.20\n",
            "Ep 1 (Step 000040):Train Loss 6.496,Val loss 7.17\n",
            "Ep 1 (Step 000045):Train Loss 6.331,Val loss 7.08\n",
            "Ep 1 (Step 000050):Train Loss 6.154,Val loss 7.02\n",
            "Ep 1 (Step 000055):Train Loss 5.990,Val loss 6.99\n",
            "Ep 1 (Step 000060):Train Loss 6.182,Val loss 6.94\n",
            "Ep 1 (Step 000065):Train Loss 6.158,Val loss 6.89\n",
            "Ep 1 (Step 000070):Train Loss 6.055,Val loss 6.85\n",
            "Ep 1 (Step 000075):Train Loss 5.944,Val loss 6.81\n",
            "Ep 1 (Step 000080):Train Loss 6.000,Val loss 6.78\n",
            "Ep 1 (Step 000085):Train Loss 5.729,Val loss 6.80\n",
            "Ep 1 (Step 000090):Train Loss 6.010,Val loss 6.67\n",
            "Ep 1 (Step 000095):Train Loss 5.633,Val loss 6.63\n",
            "Ep 1 (Step 000100):Train Loss 6.000,Val loss 6.64\n",
            "Ep 1 (Step 000105):Train Loss 5.870,Val loss 6.57\n",
            "Ep 1 (Step 000110):Train Loss 5.669,Val loss 6.55\n",
            "Ep 1 (Step 000115):Train Loss 5.682,Val loss 6.51\n",
            "I am a sick        â€ â€ â€ â€ â€ â€ â€ â€ â€ â€ â€ â€ â€ â€ \n",
            "Ep 2 (Step 000120):Train Loss 5.541,Val loss 6.51\n",
            "Ep 2 (Step 000125):Train Loss 5.637,Val loss 6.52\n",
            "Ep 2 (Step 000130):Train Loss 5.638,Val loss 6.57\n",
            "Ep 2 (Step 000135):Train Loss 5.544,Val loss 6.53\n",
            "Ep 2 (Step 000140):Train Loss 5.890,Val loss 6.50\n",
            "Ep 2 (Step 000145):Train Loss 5.361,Val loss 6.49\n",
            "Ep 2 (Step 000150):Train Loss 5.523,Val loss 6.53\n",
            "Ep 2 (Step 000155):Train Loss 5.291,Val loss 6.51\n",
            "Ep 2 (Step 000160):Train Loss 5.198,Val loss 6.56\n",
            "Ep 2 (Step 000165):Train Loss 5.205,Val loss 6.49\n",
            "Ep 2 (Step 000170):Train Loss 5.351,Val loss 6.50\n",
            "Ep 2 (Step 000175):Train Loss 5.385,Val loss 6.50\n",
            "Ep 2 (Step 000180):Train Loss 5.228,Val loss 6.47\n",
            "Ep 2 (Step 000185):Train Loss 5.290,Val loss 6.53\n",
            "Ep 2 (Step 000190):Train Loss 5.423,Val loss 6.47\n",
            "Ep 2 (Step 000195):Train Loss 5.343,Val loss 6.50\n",
            "Ep 2 (Step 000200):Train Loss 5.211,Val loss 6.47\n",
            "Ep 2 (Step 000205):Train Loss 5.285,Val loss 6.45\n",
            "Ep 2 (Step 000210):Train Loss 5.087,Val loss 6.51\n",
            "Ep 2 (Step 000215):Train Loss 5.477,Val loss 6.43\n",
            "Ep 2 (Step 000220):Train Loss 5.148,Val loss 6.41\n",
            "Ep 2 (Step 000225):Train Loss 5.196,Val loss 6.42\n",
            "Ep 2 (Step 000230):Train Loss 5.271,Val loss 6.35\n",
            "Ep 2 (Step 000235):Train Loss 5.032,Val loss 6.37\n",
            "I am a sick, to, and to to the room, and the room, and to to the room, and the room, and the room, and to the room, and the room, and to the room, and the\n",
            "Ep 3 (Step 000240):Train Loss 5.327,Val loss 6.31\n",
            "Ep 3 (Step 000245):Train Loss 5.195,Val loss 6.37\n",
            "Ep 3 (Step 000250):Train Loss 5.134,Val loss 6.31\n",
            "Ep 3 (Step 000255):Train Loss 5.122,Val loss 6.34\n",
            "Ep 3 (Step 000260):Train Loss 5.007,Val loss 6.39\n",
            "Ep 3 (Step 000265):Train Loss 5.174,Val loss 6.41\n",
            "Ep 3 (Step 000270):Train Loss 4.954,Val loss 6.36\n",
            "Ep 3 (Step 000275):Train Loss 5.047,Val loss 6.39\n",
            "Ep 3 (Step 000280):Train Loss 4.911,Val loss 6.35\n",
            "Ep 3 (Step 000285):Train Loss 5.104,Val loss 6.31\n",
            "Ep 3 (Step 000290):Train Loss 4.778,Val loss 6.31\n",
            "Ep 3 (Step 000295):Train Loss 4.773,Val loss 6.32\n",
            "Ep 3 (Step 000300):Train Loss 4.849,Val loss 6.37\n",
            "Ep 3 (Step 000305):Train Loss 4.998,Val loss 6.35\n",
            "Ep 3 (Step 000310):Train Loss 4.917,Val loss 6.32\n",
            "Ep 3 (Step 000315):Train Loss 4.959,Val loss 6.36\n",
            "Ep 3 (Step 000320):Train Loss 4.785,Val loss 6.39\n",
            "Ep 3 (Step 000325):Train Loss 4.856,Val loss 6.30\n",
            "Ep 3 (Step 000330):Train Loss 4.783,Val loss 6.30\n",
            "Ep 3 (Step 000335):Train Loss 4.670,Val loss 6.32\n",
            "Ep 3 (Step 000340):Train Loss 4.444,Val loss 6.29\n",
            "Ep 3 (Step 000345):Train Loss 4.734,Val loss 6.30\n",
            "Ep 3 (Step 000350):Train Loss 4.666,Val loss 6.30\n",
            "Ep 3 (Step 000355):Train Loss 4.964,Val loss 6.36\n",
            "I am a sick. I am                                               \n",
            "Ep 4 (Step 000360):Train Loss 4.648,Val loss 6.35\n",
            "Ep 4 (Step 000365):Train Loss 4.739,Val loss 6.32\n",
            "Ep 4 (Step 000370):Train Loss 4.689,Val loss 6.37\n",
            "Ep 4 (Step 000375):Train Loss 4.710,Val loss 6.40\n",
            "Ep 4 (Step 000380):Train Loss 4.524,Val loss 6.41\n",
            "Ep 4 (Step 000385):Train Loss 4.720,Val loss 6.37\n",
            "Ep 4 (Step 000390):Train Loss 4.713,Val loss 6.35\n",
            "Ep 4 (Step 000395):Train Loss 4.598,Val loss 6.35\n",
            "Ep 4 (Step 000400):Train Loss 4.666,Val loss 6.35\n",
            "Ep 4 (Step 000405):Train Loss 4.689,Val loss 6.39\n",
            "Ep 4 (Step 000410):Train Loss 4.759,Val loss 6.38\n",
            "Ep 4 (Step 000415):Train Loss 4.825,Val loss 6.38\n",
            "Ep 4 (Step 000420):Train Loss 4.536,Val loss 6.39\n",
            "Ep 4 (Step 000425):Train Loss 4.668,Val loss 6.37\n",
            "Ep 4 (Step 000430):Train Loss 4.377,Val loss 6.38\n",
            "Ep 4 (Step 000435):Train Loss 4.467,Val loss 6.41\n",
            "Ep 4 (Step 000440):Train Loss 4.492,Val loss 6.35\n",
            "Ep 4 (Step 000445):Train Loss 4.567,Val loss 6.32\n",
            "Ep 4 (Step 000450):Train Loss 4.614,Val loss 6.28\n",
            "Ep 4 (Step 000455):Train Loss 4.390,Val loss 6.32\n",
            "Ep 4 (Step 000460):Train Loss 4.279,Val loss 6.31\n",
            "Ep 4 (Step 000465):Train Loss 4.496,Val loss 6.28\n",
            "Ep 4 (Step 000470):Train Loss 4.295,Val loss 6.28\n",
            "Ep 4 (Step 000475):Train Loss 4.295,Val loss 6.32\n",
            "I am a sick, and, and, and                   â€œWhy,â€ I was in the contrary, that I was not the contrary, I was in the contrary,\n",
            "Ep 5 (Step 000480):Train Loss 4.176,Val loss 6.29\n",
            "Ep 5 (Step 000485):Train Loss 4.271,Val loss 6.30\n",
            "Ep 5 (Step 000490):Train Loss 3.999,Val loss 6.29\n",
            "Ep 5 (Step 000495):Train Loss 4.133,Val loss 6.34\n",
            "Ep 5 (Step 000500):Train Loss 4.005,Val loss 6.33\n",
            "Ep 5 (Step 000505):Train Loss 3.889,Val loss 6.31\n",
            "Ep 5 (Step 000510):Train Loss 4.010,Val loss 6.32\n",
            "Ep 5 (Step 000515):Train Loss 3.978,Val loss 6.36\n",
            "Ep 5 (Step 000520):Train Loss 3.988,Val loss 6.35\n",
            "Ep 5 (Step 000525):Train Loss 3.742,Val loss 6.40\n",
            "Ep 5 (Step 000530):Train Loss 4.170,Val loss 6.45\n",
            "Ep 5 (Step 000535):Train Loss 3.960,Val loss 6.43\n",
            "Ep 5 (Step 000540):Train Loss 4.229,Val loss 6.43\n",
            "Ep 5 (Step 000545):Train Loss 3.793,Val loss 6.37\n",
            "Ep 5 (Step 000550):Train Loss 3.874,Val loss 6.35\n",
            "Ep 5 (Step 000555):Train Loss 3.943,Val loss 6.41\n",
            "Ep 5 (Step 000560):Train Loss 4.033,Val loss 6.38\n",
            "Ep 5 (Step 000565):Train Loss 3.768,Val loss 6.42\n",
            "Ep 5 (Step 000570):Train Loss 3.931,Val loss 6.39\n",
            "Ep 5 (Step 000575):Train Loss 3.883,Val loss 6.36\n",
            "Ep 5 (Step 000580):Train Loss 3.813,Val loss 6.39\n",
            "Ep 5 (Step 000585):Train Loss 3.701,Val loss 6.35\n",
            "Ep 5 (Step 000590):Train Loss 3.523,Val loss 6.36\n",
            "I am a sick â€œI will â€ I am,â€œI am not to me to â€œI am a year you will â€ â€œOh,â€œOh,â€œYou will â€œWhy,ï¿½\n",
            "Ep 6 (Step 000595):Train Loss 3.746,Val loss 6.33\n",
            "Ep 6 (Step 000600):Train Loss 3.806,Val loss 6.38\n",
            "Ep 6 (Step 000605):Train Loss 3.405,Val loss 6.41\n",
            "Ep 6 (Step 000610):Train Loss 3.468,Val loss 6.40\n",
            "Ep 6 (Step 000615):Train Loss 3.495,Val loss 6.42\n",
            "Ep 6 (Step 000620):Train Loss 3.318,Val loss 6.43\n",
            "Ep 6 (Step 000625):Train Loss 3.654,Val loss 6.39\n",
            "Ep 6 (Step 000630):Train Loss 3.435,Val loss 6.44\n",
            "Ep 6 (Step 000635):Train Loss 3.490,Val loss 6.48\n",
            "Ep 6 (Step 000640):Train Loss 3.262,Val loss 6.46\n",
            "Ep 6 (Step 000645):Train Loss 3.338,Val loss 6.44\n",
            "Ep 6 (Step 000650):Train Loss 3.461,Val loss 6.47\n",
            "Ep 6 (Step 000655):Train Loss 3.552,Val loss 6.48\n",
            "Ep 6 (Step 000660):Train Loss 3.284,Val loss 6.52\n",
            "Ep 6 (Step 000665):Train Loss 3.063,Val loss 6.51\n",
            "Ep 6 (Step 000670):Train Loss 3.092,Val loss 6.51\n",
            "Ep 6 (Step 000675):Train Loss 3.444,Val loss 6.47\n",
            "Ep 6 (Step 000680):Train Loss 3.225,Val loss 6.52\n",
            "Ep 6 (Step 000685):Train Loss 2.962,Val loss 6.44\n",
            "Ep 6 (Step 000690):Train Loss 3.098,Val loss 6.48\n",
            "Ep 6 (Step 000695):Train Loss 3.262,Val loss 6.48\n",
            "Ep 6 (Step 000700):Train Loss 3.094,Val loss 6.47\n",
            "Ep 6 (Step 000705):Train Loss 3.100,Val loss 6.51\n",
            "Ep 6 (Step 000710):Train Loss 3.104,Val loss 6.45\n",
            "I am a sickly, in the same time I was and that that I was in the all this very different of the and, in the and so I was so on the same time to be reconciled to be reconciled to see, but\n",
            "Ep 7 (Step 000715):Train Loss 2.959,Val loss 6.47\n",
            "Ep 7 (Step 000720):Train Loss 3.091,Val loss 6.51\n",
            "Ep 7 (Step 000725):Train Loss 2.863,Val loss 6.56\n",
            "Ep 7 (Step 000730):Train Loss 2.905,Val loss 6.55\n",
            "Ep 7 (Step 000735):Train Loss 2.707,Val loss 6.57\n",
            "Ep 7 (Step 000740):Train Loss 2.816,Val loss 6.58\n",
            "Ep 7 (Step 000745):Train Loss 2.589,Val loss 6.62\n",
            "Ep 7 (Step 000750):Train Loss 2.592,Val loss 6.59\n",
            "Ep 7 (Step 000755):Train Loss 2.587,Val loss 6.63\n",
            "Ep 7 (Step 000760):Train Loss 2.564,Val loss 6.63\n",
            "Ep 7 (Step 000765):Train Loss 2.850,Val loss 6.61\n",
            "Ep 7 (Step 000770):Train Loss 3.083,Val loss 6.57\n",
            "Ep 7 (Step 000775):Train Loss 2.579,Val loss 6.60\n",
            "Ep 7 (Step 000780):Train Loss 2.356,Val loss 6.62\n",
            "Ep 7 (Step 000785):Train Loss 2.610,Val loss 6.65\n",
            "Ep 7 (Step 000790):Train Loss 2.434,Val loss 6.63\n",
            "Ep 7 (Step 000795):Train Loss 2.400,Val loss 6.64\n",
            "Ep 7 (Step 000800):Train Loss 2.649,Val loss 6.66\n",
            "Ep 7 (Step 000805):Train Loss 2.608,Val loss 6.66\n",
            "Ep 7 (Step 000810):Train Loss 2.266,Val loss 6.64\n",
            "Ep 7 (Step 000815):Train Loss 2.228,Val loss 6.63\n",
            "Ep 7 (Step 000820):Train Loss 2.255,Val loss 6.64\n",
            "Ep 7 (Step 000825):Train Loss 2.269,Val loss 6.70\n",
            "Ep 7 (Step 000830):Train Loss 2.295,Val loss 6.64\n",
            "I am a sickble, and that it was so on I was a sick man? Why are still in the same time the same I was a man, and with the same. heve to be in the same time to be But as\n",
            "Ep 8 (Step 000835):Train Loss 2.276,Val loss 6.66\n",
            "Ep 8 (Step 000840):Train Loss 1.977,Val loss 6.68\n",
            "Ep 8 (Step 000845):Train Loss 2.257,Val loss 6.73\n",
            "Ep 8 (Step 000850):Train Loss 1.927,Val loss 6.76\n",
            "Ep 8 (Step 000855):Train Loss 2.136,Val loss 6.81\n",
            "Ep 8 (Step 000860):Train Loss 1.787,Val loss 6.80\n",
            "Ep 8 (Step 000865):Train Loss 2.055,Val loss 6.80\n",
            "Ep 8 (Step 000870):Train Loss 1.930,Val loss 6.83\n",
            "Ep 8 (Step 000875):Train Loss 1.854,Val loss 6.87\n",
            "Ep 8 (Step 000880):Train Loss 1.657,Val loss 6.83\n",
            "Ep 8 (Step 000885):Train Loss 1.861,Val loss 6.90\n",
            "Ep 8 (Step 000890):Train Loss 1.574,Val loss 6.90\n",
            "Ep 8 (Step 000895):Train Loss 2.038,Val loss 6.84\n",
            "Ep 8 (Step 000900):Train Loss 2.021,Val loss 6.93\n",
            "Ep 8 (Step 000905):Train Loss 1.877,Val loss 6.88\n",
            "Ep 8 (Step 000910):Train Loss 1.897,Val loss 6.89\n",
            "Ep 8 (Step 000915):Train Loss 1.553,Val loss 6.88\n",
            "Ep 8 (Step 000920):Train Loss 1.603,Val loss 6.92\n",
            "Ep 8 (Step 000925):Train Loss 1.608,Val loss 6.95\n",
            "Ep 8 (Step 000930):Train Loss 1.751,Val loss 6.97\n",
            "Ep 8 (Step 000935):Train Loss 1.817,Val loss 6.94\n",
            "Ep 8 (Step 000940):Train Loss 1.392,Val loss 6.96\n",
            "Ep 8 (Step 000945):Train Loss 1.640,Val loss 6.95\n",
            "Ep 8 (Step 000950):Train Loss 1.468,Val loss 6.98\n",
            "I am a sickly so I am a girl on at and that my head of course, I should have a for my face, and so. But now, I should have been that I should go. I should have been positively surprised at my duty to\n",
            "Ep 9 (Step 000955):Train Loss 1.609,Val loss 7.00\n",
            "Ep 9 (Step 000960):Train Loss 1.325,Val loss 7.05\n",
            "Ep 9 (Step 000965):Train Loss 1.253,Val loss 7.04\n",
            "Ep 9 (Step 000970):Train Loss 1.464,Val loss 7.07\n",
            "Ep 9 (Step 000975):Train Loss 1.019,Val loss 7.16\n",
            "Ep 9 (Step 000980):Train Loss 1.237,Val loss 7.17\n",
            "Ep 9 (Step 000985):Train Loss 1.147,Val loss 7.16\n",
            "Ep 9 (Step 000990):Train Loss 1.422,Val loss 7.16\n",
            "Ep 9 (Step 000995):Train Loss 1.168,Val loss 7.19\n",
            "Ep 9 (Step 001000):Train Loss 1.053,Val loss 7.19\n",
            "Ep 9 (Step 001005):Train Loss 1.289,Val loss 7.18\n",
            "Ep 9 (Step 001010):Train Loss 1.305,Val loss 7.21\n",
            "Ep 9 (Step 001015):Train Loss 0.840,Val loss 7.15\n",
            "Ep 9 (Step 001020):Train Loss 1.228,Val loss 7.18\n",
            "Ep 9 (Step 001025):Train Loss 0.891,Val loss 7.22\n",
            "Ep 9 (Step 001030):Train Loss 1.014,Val loss 7.26\n",
            "Ep 9 (Step 001035):Train Loss 1.241,Val loss 7.28\n",
            "Ep 9 (Step 001040):Train Loss 0.902,Val loss 7.20\n",
            "Ep 9 (Step 001045):Train Loss 1.108,Val loss 7.27\n",
            "Ep 9 (Step 001050):Train Loss 1.023,Val loss 7.26\n",
            "Ep 9 (Step 001055):Train Loss 1.089,Val loss 7.26\n",
            "Ep 9 (Step 001060):Train Loss 0.799,Val loss 7.27\n",
            "Ep 9 (Step 001065):Train Loss 0.933,Val loss 7.22\n",
            "Ep 9 (Step 001070):Train Loss 0.932,Val loss 7.29\n",
            "I am a sick-room, where there was only one candle burning, and stood still more advantageousently a good?â€ â€™s ready to be,â€ she answered,â€™s. â€™s a slave!â€œYes\n",
            "Ep 10 (Step 001075):Train Loss 0.904,Val loss 7.32\n",
            "Ep 10 (Step 001080):Train Loss 0.918,Val loss 7.37\n",
            "Ep 10 (Step 001085):Train Loss 0.763,Val loss 7.38\n",
            "Ep 10 (Step 001090):Train Loss 0.666,Val loss 7.40\n",
            "Ep 10 (Step 001095):Train Loss 0.748,Val loss 7.40\n",
            "Ep 10 (Step 001100):Train Loss 0.660,Val loss 7.44\n",
            "Ep 10 (Step 001105):Train Loss 0.638,Val loss 7.48\n",
            "Ep 10 (Step 001110):Train Loss 0.794,Val loss 7.49\n",
            "Ep 10 (Step 001115):Train Loss 0.733,Val loss 7.44\n",
            "Ep 10 (Step 001120):Train Loss 0.684,Val loss 7.48\n",
            "Ep 10 (Step 001125):Train Loss 0.638,Val loss 7.49\n",
            "Ep 10 (Step 001130):Train Loss 0.603,Val loss 7.48\n",
            "Ep 10 (Step 001135):Train Loss 0.661,Val loss 7.52\n",
            "Ep 10 (Step 001140):Train Loss 0.603,Val loss 7.52\n",
            "Ep 10 (Step 001145):Train Loss 0.601,Val loss 7.55\n",
            "Ep 10 (Step 001150):Train Loss 0.660,Val loss 7.54\n",
            "Ep 10 (Step 001155):Train Loss 0.611,Val loss 7.56\n",
            "Ep 10 (Step 001160):Train Loss 0.560,Val loss 7.60\n",
            "Ep 10 (Step 001165):Train Loss 0.461,Val loss 7.59\n",
            "Ep 10 (Step 001170):Train Loss 0.476,Val loss 7.55\n",
            "Ep 10 (Step 001175):Train Loss 0.415,Val loss 7.58\n",
            "Ep 10 (Step 001180):Train Loss 0.691,Val loss 7.55\n",
            "Ep 10 (Step 001185):Train Loss 0.497,Val loss 7.58\n",
            "I am a sick-gown round me out of sheer? But that distant relation another three months; and good luck on the  for the most other times I was in my desires, for a they had put myself publicly on an equal\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=0.0004,weight_decay=0.1\n",
        ")\n",
        "num_epochs = 10\n",
        "train_losses,val_losses,tokens_seen = train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    device,\n",
        "    num_epochs=num_epochs,\n",
        "    eval_freq=5,\n",
        "    eval_iter=5,\n",
        "    start_context=\"I am a sick\",\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##plotting curves\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def plot_losses(epochs_seen,tokens_seen,train_losses,val_losses):\n",
        "  fig,ax1 = plt.subplots(figsize=(5,3))\n",
        "  ax1.plot(epochs_seen,train_losses,label=\"Training Loss\")\n",
        "  ax1.plot(epochs_seen,val_losses,linestyle=\"-.\",label=\"Validation loss\")\n",
        "\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(tokens_seen,train_losses,alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
        "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "r99cA_o9t9Z5",
        "outputId": "3a02b58a-6fe1-4486-b9d5-4b0ae868eb0d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAEiCAYAAAAyI0HeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAa65JREFUeJzt3Xd4U2X7wPFvku69F6XMQqFsCggFRUCGiIAoqKjgQrGIiCIulgsnLz/Hi+IAfQERUBBlL0H2LLOUVWiBLkYnncnz++PQlEiRUgoJ5f5cVy579n1iyJ3nPEunlFIIIYQQwqborR2AEEIIIS4nCVoIIYSwQZKghRBCCBskCVoIIYSwQZKghRBCCBskCVoIIYSwQZKghRBCCBskCVoIIYSwQZKghRBCCBskCVqIW9Tx48fR6XTExsZaOxQhxA0gCVoIK9LpdP/6Gj9+vLVDFEJYiZ21AxDidpacnGz++5dffmHs2LHEx8eb17m5uVkjLCGEDZAStBBWFBQUZH55enqi0+nMywEBAUyaNInQ0FAcHR1p1qwZS5cuveK5jEYjTz31FBERESQmJgLw+++/06JFC5ycnKhduzYTJkyguLjYfIxOp+O7776jb9++uLi4EB4ezsKFC83bz58/z8CBA/H398fZ2Znw8HCmTZt2xRjmzZtH48aNcXZ2xtfXly5dupCbm2ve/t1339GgQQOcnJyIiIjgv//9r8XxSUlJ9O/fHy8vL3x8fOjduzfHjx83bx88eDB9+vTh008/JTg4GF9fX2JiYigqKir3ey7ELUMJIWzCtGnTlKenp3l50qRJysPDQ/3888/q4MGD6rXXXlP29vbq0KFDSimlEhISFKB27dql8vPzVd++fVXz5s1VWlqaUkqpdevWKQ8PDzV9+nR19OhRtXz5clWzZk01fvx48zUAFRoaqmbNmqUOHz6shg8frtzc3NTZs2eVUkrFxMSoZs2aqW3btqmEhAS1YsUKtXDhwjLjP336tLKzs1OTJk1SCQkJas+ePeqrr75S2dnZSimlZsyYoYKDg9Wvv/6qjh07pn799Vfl4+Ojpk+frpRSqrCwUDVo0EA99dRTas+ePerAgQPq0UcfVfXr11cFBQVKKaUGDRqkPDw81PPPP6/i4uLUH3/8oVxcXNTUqVMr93+GEDZAErQQNuKfCTokJES9//77Fvu0atVKvfDCC0qp0gT9999/q86dO6v27durjIwM876dO3dWH3zwgcXx//vf/1RwcLB5GVBvv/22eTknJ0cBasmSJUoppXr16qWefPLJcsW/Y8cOBajjx4+Xub1OnTpq1qxZFuveffdd1bZtW3Ns9evXVyaTyby9oKBAOTs7q2XLlimltARdo0YNVVxcbN7noYceUgMGDChXjELcSqQOWggblJWVxenTp4mOjrZYHx0dze7duy3WPfLII4SGhrJ69WqcnZ3N63fv3s2GDRt4//33zeuMRiP5+flcuHABFxcXAJo0aWLe7urqioeHB2lpaQAMHTqUfv36sXPnTrp27UqfPn1o165dmTE3bdqUzp0707hxY7p160bXrl158MEH8fb2Jjc3l6NHj/L000/z7LPPmo8pLi7G09PTHO+RI0dwd3e3OG9+fj5Hjx41L0dGRmIwGMzLwcHB7N2791/eTSFuTZKghbjF3XvvvcyYMYNNmzbRqVMn8/qcnBwmTJjAAw88cNkxTk5O5r/t7e0ttul0OkwmEwA9evTgxIkTLF68mBUrVtC5c2diYmL49NNPLzunwWBgxYoVbNy4keXLl/PFF1/w1ltvsWXLFvOPgW+//ZY2bdpcdlxJvC1btmTmzJmXndvf379c8QpRlUiCFsIGeXh4EBISwoYNG7jrrrvM6zds2EDr1q0t9h06dCiNGjXi/vvvZ9GiReb9W7RoQXx8PHXr1r2uWPz9/Rk0aBCDBg2iQ4cOjBo1qswEDVqyjI6OJjo6mrFjx1KjRg3mz5/PyJEjCQkJ4dixYwwcOLDMY1u0aMEvv/xCQEAAHh4e1xWzEFWBJGghbNSoUaMYN24cderUoVmzZkybNo3Y2NgyS5gvvvgiRqOR++67jyVLltC+fXvGjh3LfffdR1hYGA8++CB6vZ7du3ezb98+3nvvvXLFMHbsWFq2bElkZCQFBQX8+eefNGjQoMx9t2zZwqpVq+jatSsBAQFs2bKF9PR08/4TJkxg+PDheHp60r17dwoKCti+fTvnz59n5MiRDBw4kE8++YTevXvzzjvvEBoayokTJ/jtt9947bXXCA0NrfibKcQtSBK0EDZq+PDhZGZm8sorr5CWlkbDhg1ZuHAh4eHhZe4/YsQITCYT9957L0uXLqVbt278+eefvPPOO3z00UfY29sTERHBM888U+4YHBwceOONNzh+/DjOzs506NCB2bNnl7mvh4cH69atY/LkyWRlZVGjRg0+++wzevToAcAzzzyDi4sLn3zyCaNGjcLV1ZXGjRszYsQIAFxcXFi3bh2jR4/mgQceIDs7m2rVqtG5c2cpUYvbkk4ppawdhBBCCCEsyUAlQgghhA2SBC2EEELYIEnQQgghhA2SBC2EEELYIEnQQgghhA2SBC2EEELYIEnQ5fTVV19Rs2ZNnJycaNOmDVu3brV2SBbWrVtHr169CAkJQafTsWDBAovtSinGjh1LcHAwzs7OdOnShcOHD1vsc+7cOQYOHIiHhwdeXl48/fTT5OTkWOyzZ88eOnTogJOTE9WrV+fjjz++LJa5c+cSERGBk5MTjRs3ZvHixdccS3lNnDiRVq1a4e7uTkBAAH369LGYTxm0sZxjYmLw9fXFzc2Nfv36kZqaarFPYmIiPXv2xMXFhYCAAEaNGmUxLSPAX3/9RYsWLXB0dKRu3bpMnz79sniu9jkpTyzlNWXKFJo0aYKHhwceHh60bduWJUuWVPn7/qcPP/wQnU5n7k9dle99/Pjx6HQ6i1dERESVv+8Sp06d4rHHHsPX1xdnZ2caN27M9u3bzdur3PecNWfquFXMnj1bOTg4qB9++EHt379fPfvss8rLy0ulpqZaOzSzxYsXq7feekv99ttvClDz58+32P7hhx8qT09PtWDBArV79251//33q1q1aqm8vDzzPt27d1dNmzZVmzdvVn///beqW7eueuSRR8zbMzMzVWBgoBo4cKDat2+f+vnnn5Wzs7P65ptvzPts2LBBGQwG9fHHH6sDBw6ot99+W9nb26u9e/deUyzl1a1bNzVt2jS1b98+FRsbq+69914VFhamcnJyzPs8//zzqnr16mrVqlVq+/bt6o477lDt2rUzby8uLlaNGjVSXbp0Ubt27VKLFy9Wfn5+6o033jDvc+zYMeXi4qJGjhypDhw4oL744gtlMBjU0qVLzfuU53NytViuxcKFC9WiRYvUoUOHVHx8vHrzzTeVvb292rdvX5W+70tt3bpV1axZUzVp0kS99NJL5b7erXrv48aNU5GRkSo5Odn8Sk9Pr/L3rZRS586dUzVq1FCDBw9WW7ZsUceOHVPLli1TR44cMe9T1b7nJEGXQ+vWrVVMTIx52Wg0qpCQEDVx4kQrRnVl/0zQJpNJBQUFqU8++cS8LiMjQzk6Oqqff/5ZKaXUgQMHFKC2bdtm3mfJkiVKp9OpU6dOKaWU+u9//6u8vb3Nc/MqpdTo0aNV/fr1zcv9+/dXPXv2tIinTZs26rnnnit3LNcjLS1NAWrt2rXmc9vb26u5c+ea94mLi1OA2rRpk1JK+3Gj1+tVSkqKeZ8pU6YoDw8P872+9tprKjIy0uJaAwYMUN26dTMvX+1zUp5Yrpe3t7f67rvvbov7zs7OVuHh4WrFihXqrrvuMifoqnzv48aNU02bNi1zW1W+b6W075r27dtfcXtV/J6TR9xXUVhYyI4dO+jSpYt5nV6vp0uXLmzatMmKkZVfQkICKSkpFvfg6elJmzZtzPewadMmvLy8iIqKMu/TpUsX9Ho9W7ZsMe9z55134uDgYN6nW7duxMfHc/78efM+l16nZJ+S65QnluuRmZkJgI+PDwA7duygqKjI4noRERGEhYVZ3Hvjxo0JDAy0iDkrK4v9+/eX677K8zkpTywVZTQamT17Nrm5ubRt2/a2uO+YmBh69ux5WXxV/d4PHz5MSEgItWvXZuDAgSQmJt4W971w4UKioqJ46KGHCAgIoHnz5nz77bfm7VXxe04S9FWcOXMGo9Fo8YEGCAwMJCUlxUpRXZuSOP/tHlJSUggICLDYbmdnh4+Pj8U+ZZ3j0mtcaZ9Lt18tlooymUyMGDGC6OhoGjVqZL6eg4MDXl5e/xpTRe8rKyuLvLy8cn1OyhPLtdq7dy9ubm44Ojry/PPPM3/+fBo2bFjl73v27Nns3LmTiRMnXratKt97mzZtmD59OkuXLmXKlCkkJCTQoUMHsrOzq/R9Axw7dowpU6YQHh7OsmXLGDp0KMOHD+fHH3+0iL8qfc/JZBmiyoiJiWHfvn2sX7/e2qHcNPXr1yc2NpbMzEzmzZvHoEGDWLt2rbXDuqGSkpJ46aWXWLFihcW81reDkolHAJo0aUKbNm2oUaMGc+bMwdnZ2YqR3Xgmk4moqCg++OADAJo3b86+ffv4+uuvGTRokJWjuzGkBH0Vfn5+GAyGy1ofpqamEhQUZKWork1JnP92D0FBQaSlpVlsLy4u5ty5cxb7lHWOS69xpX0u3X61WCpi2LBh/Pnnn6xZs8ZiWsKgoCAKCwvJyMj415gqel8eHh44OzuX63NSnliulYODA3Xr1qVly5ZMnDiRpk2b8n//939V+r537NhBWloaLVq0wM7ODjs7O9auXcvnn3+OnZ0dgYGBVfbe/8nLy4t69epx5MiRKv3/HCA4OJiGDRtarGvQoIH5EX9V/J6TBH0VDg4OtGzZklWrVpnXmUwmVq1aRdu2ba0YWfnVqlWLoKAgi3vIyspiy5Yt5nto27YtGRkZ7Nixw7zP6tWrMZlMtGnTxrzPunXrKCoqMu+zYsUK6tevj7e3t3mfS69Tsk/JdcoTy7VQSjFs2DDmz5/P6tWrqVWrlsX2li1bYm9vb3G9+Ph4EhMTLe597969Fv9wV6xYgYeHh/kL4Wr3VZ7PSXliuV4mk4mCgoIqfd+dO3dm7969xMbGml9RUVEMHDjQ/HdVvfd/ysnJ4ejRowQHB1fp/+cA0dHRl3WhPHToEDVq1ACq6PdcuZuT3cZmz56tHB0d1fTp09WBAwfUkCFDlJeXl0VLSGvLzs5Wu3btUrt27VKAmjRpktq1a5c6ceKEUkpr8u/l5aV+//13tWfPHtW7d+8yux80b95cbdmyRa1fv16Fh4dbdD/IyMhQgYGB6vHHH1f79u1Ts2fPVi4uLpd1P7Czs1OffvqpiouLU+PGjSuz+8HVYimvoUOHKk9PT/XXX39ZdD25cOGCeZ/nn39ehYWFqdWrV6vt27ertm3bqrZt25q3l3Q96dq1q4qNjVVLly5V/v7+ZXY9GTVqlIqLi1NfffVVmV1PrvY5uVos1+L1119Xa9euVQkJCWrPnj3q9ddfVzqdTi1fvrxK33dZLm3FXZXv/ZVXXlF//fWXSkhIUBs2bFBdunRRfn5+Ki0trUrft1Jalzo7Ozv1/vvvq8OHD6uZM2cqFxcXNWPGDPM+Ve17ThJ0OX3xxRcqLCxMOTg4qNatW6vNmzdbOyQLa9asUcBlr0GDBimltGb/Y8aMUYGBgcrR0VF17txZxcfHW5zj7Nmz6pFHHlFubm7Kw8NDPfnkkyo7O9tin927d6v27dsrR0dHVa1aNfXhhx9eFsucOXNUvXr1lIODg4qMjFSLFi2y2F6eWMqrrHsG1LRp08z75OXlqRdeeEF5e3srFxcX1bdvX5WcnGxxnuPHj6sePXooZ2dn5efnp1555RVVVFRksc+aNWtUs2bNlIODg6pdu7bFNUpc7XNSnljK66mnnlI1atRQDg4Oyt/fX3Xu3NmcnKvyfZflnwm6qt77gAEDVHBwsHJwcFDVqlVTAwYMsOgHXFXvu8Qff/yhGjVqpBwdHVVERISaOnWqxfaq9j2nU0qp8pe3hRBCCHEzSB20EEIIYYMkQQshhBA2SBK0EEIIYYMkQQshhBA2SBK0EEIIYYMkQQshhBA2SBL0NSgoKGD8+PEUFBRYO5Sb6na9b5B7vx3v/Xa9b5B7t7V7l37Q1yArKwtPT08yMzPx8PCwdjg3ze163yD3fjve++163yD3bmv3LiVoIYQQwgZJghZCCCFsUJWfD7q4uJhdu3YRGBiIXn99v0eys7MBOHXqFFlZWZUR3i3hdr1vkHuH2+/eb9f7Brl3uHH3bjKZSE1NpXnz5tjZlS/1Vvk66G3bttG6dWtrhyGEEEKwdetWWrVqVa59q3wJOjAwENDelODgYCtHI4QQ4naUnJxM69atzTmpPKp8gi55rB0cHExoaKiVoxFCCHE7u5aqVqs2Elu3bh29evUiJCQEnU7HggULLLYrpRg7dizBwcE4OzvTpUsXDh8+bJ1ghRBCiJvIqgk6NzeXpk2b8tVXX5W5/eOPP+bzzz/n66+/ZsuWLbi6utKtWzfy8/NvcqRCCCHEzWXVR9w9evSgR48eZW5TSjF58mTefvttevfuDcBPP/1EYGAgCxYs4OGHH76ZoQohhBA3lc3WQSckJJCSkkKXLl3M6zw9PWnTpg2bNm26YoIuKCiwGKqtpOm8EEL8k8lkorCw0NphiCrA3t4eg8FQqee02QSdkpICcFmLt8DAQPO2skycOJEJEyZUejx5hUa2nzhHYbGJzg3K3wpPCGGbCgsLSUhIwGQyWTsUUUV4eXkRFBSETqerlPPZbIKuqDfeeIORI0eal0+dOkXDhg2v+7zp2QU8/v1WnOz1HHy37MfyQohbg1KK5ORkDAYD1atXv+5BjMTtTSnFhQsXSEtLA6i0Lr02m6CDgoIASE1NtbjZ1NRUmjVrdsXjHB0dcXR0NC9X1ogw7oYiHtCvw82UR5GxG/YG+QctxK2quLiYCxcuEBISgouLi7XDEVWAs7MzAGlpaQQEBFTK426bzTK1atUiKCiIVatWmddlZWWxZcsW2rZte9PjcbM3Mcnha96x/5GcnJybfn0hROUxGo0AODg4WDkSUZWU/NgrKiqqlPNZtQSdk5PDkSNHzMsJCQnExsbi4+NDWFgYI0aM4L333iM8PJxatWoxZswYQkJC6NOnz02P1d7ZE5PSodcpcrPO4+1pG9ORCSEqrrLqCoWAyv88WTVBb9++nbvvvtu8XFJ3PGjQIKZPn85rr71Gbm4uQ4YMISMjg/bt27N06VKcnJxufrB6PTk6FzzI5ULWWaDGzY9BCCHEbcOqj7g7duyIUuqy1/Tp0wHt18g777xDSkoK+fn5rFy5knr16lkt3lydKwAF2eetFoMQQlSmmjVrMnny5HLv/9dff6HT6cjIyLhhMQmNzdZB26I8gxsAhbnnrByJEOJ2o9Pp/vU1fvz4Cp1327ZtDBkypNz7t2vXjuTkZDw9PSt0vfKSHwI23IrbFuUb3KEYinMzrB2KEOI2k5ycbP77l19+YezYscTHx5vXubm5mf9WSmE0Gss177C/v/81xeHg4GDuZSNuLClBX4NCO3cAjHkZ1g1ECHHbCQoKMr88PT3R6XTm5YMHD+Lu7s6SJUto2bIljo6OrF+/nqNHj9K7d28CAwNxc3OjVatWrFy50uK8/3zErdPp+O677+jbty8uLi6Eh4ezcOFC8/Z/lmynT5+Ol5cXy5Yto0GDBri5udG9e3eLHxTFxcUMHz4cLy8vfH19GT16NIMGDbquBr/nz5/niSeewNvbGxcXF3r06GExmdKJEyfo1asX3t7euLq6EhkZyeLFi83HDhw4EH9/f5ydnQkPD2fatGkVjuVGkQR9DYodtASNJGghqhSlFBcKi63yUkpV2n28/vrrfPjhh8TFxdGkSRNycnK49957WbVqFbt27aJ79+706tWLxMTEfz3PhAkT6N+/P3v27OHee+9l4MCBnDt35aq9Cxcu8Omnn/K///2PdevWkZiYyKuvvmre/tFHHzFz5kymTZvGhg0byMrKumz2wms1ePBgtm/fzsKFC9m0aRNKKe69915zF6eYmBgKCgpYt24de/fu5aOPPjI/ZRgzZgwHDhxgyZIlxMXFMWXKFPz8/K4rnhtBHnFfA6P9xa5VBZnWDUQIUanyiow0HLvMKtc+8E43XBwq56v4nXfe4Z577jEv+/j40LRpU/Pyu+++y/z581m4cCHDhg274nkGDx7MI488AsAHH3zA559/ztatW+nevXuZ+xcVFfH1119Tp04dAIYNG8Y777xj3v7FF1/wxhtv0LdvXwC+/PJLc2m2Ig4fPszChQvZsGED7dq1A2DmzJlUr16dBQsW8NBDD5GYmEi/fv1o3LgxALVr1zYfn5iYSPPmzYmKigK0pwi2SErQ10A5aY0iDAWVMzqZEEJUppKEUyInJ4dXX32VBg0a4OXlhZubG3FxcVctQTdp0sT8t6urKx4eHuZhLMvi4uJiTs6gDXVZsn9mZiapqam0bt3avN1gMNCyZctrurdLxcXFYWdnR5s2bczrfH19qV+/PnFxcQAMHz6c9957j+joaMaNG8eePXvM+w4dOpTZs2fTrFkzXnvtNTZu3FjhWG4kKUFfi5IEXSQJWoiqxNnewIF3ulnt2pXF1dXVYvnVV19lxYoVfPrpp9StWxdnZ2cefPDBq87gZW9vb7Gs0+n+dVKRsvavzEf3FfHMM8/QrVs3Fi1axPLly5k4cSKfffYZL774Ij169ODEiRMsXryYFStW0LlzZ2JiYvj000+tGvM/SQn6GuidvQBwKJIpLIWoSnQ6HS4OdlZ53cjRzDZs2MDgwYPp27cvjRs3JigoiOPHj9+w65XF09OTwMBAtm3bZl5nNBrZuXNnhc/ZoEEDiouL2bJli3nd2bNniY+Pt5gcqXr16jz//PP89ttvvPLKK3z77bfmbf7+/gwaNIgZM2YwefJkpk6dWuF4bhQpQV8Dg6sPGcqVC0rG7xVC2L7w8HB+++03evXqhU6nY8yYMVaZXvPFF19k4sSJ1K1bl4iICL744gvOnz9frh8ne/fuxd3d3bys0+lo2rQpvXv35tlnn+Wbb77B3d2d119/nWrVqtG7d28ARowYQY8ePahXrx7nz59nzZo1NGjQAICxY8fSsmVLIiMjKSgo4M8//zRvsyWSoK9BQe2uNFv9LXU93Vh59d2FEMKqJk2axFNPPUW7du3w8/Nj9OjRlTbD37UYPXo0KSkpPPHEExgMBoYMGUK3bt3KNePTnXfeabFsMBgoLi5m2rRpvPTSS9x3330UFhZy5513snjxYvPjdqPRSExMDCdPnsTDw4Pu3bvzn//8B9D6cr/xxhscP34cZ2dnOnTowOzZsyv/xq+TTlm7ouAGO3nyJNWrVycpKYnQ0NDrOtfek5n0+nI9gR6ObHmzSyVFKIS42fLz80lISKBWrVrWGdv/NmcymWjQoAH9+/fn3XfftXY4lebfPlcVyUVSgr4G7k7a25WdX2zlSIQQ4tZx4sQJli9fzl133UVBQQFffvklCQkJPProo9YOzaZJgr4G7oYiZti/jzt5GAvvwuDgbO2QhBDC5un1eqZPn86rr76KUopGjRqxcuVKm6z3tSWSoK+Bu5sb7fQH0OsUWRln8Qi4vkfmQghxO6hevTobNmywdhi3HEnQ18DB3o4RphfJNDryLs54WDsgIYQQVZYk6Gu03vEuzuQUkFVsf/WdhRBCiAqSgUqukYe5oViRlSMRQghRlUkJ+hq1Mhyimf4oxnRfqO1r7XCEEEJUUZKgr9FDBfOJctjIrlMBwB3WDkcIIUQVJY+4r1GhvTbknJI5oYUQQtxAkqCvkdFBa7ut8mVOaCHEradjx46MGDHCvFyzZk0mT578r8fodDoWLFhw3deurPP8m/Hjx9OsWbMbeo2bRRL0NSp29AbALv+clSMRQtxOevXqRffu3cvc9vfff6PT6SzmPC6vbdu2MWTIkOsNz8KVkmRycjI9evSo1GtVZZKgr1GRazAALnkpVo5ECHE7efrpp1mxYgUnT568bNu0adOIioqiSZMm13xef39/XFxcKiPEqwoKCsLR0fGmXKsqkAR9jXSe1QBwK0i1ciRCiNvJfffdh7+/P9OnT7dYn5OTw9y5c3n66ac5e/YsjzzyCNWqVcPFxYXGjRvz888//+t5//mI+/Dhw9x55504OTnRsGFDVqxYcdkxo0ePpl69eri4uFC7dm3GjBlDUZHW9XT69OlMmDCB3bt3o9Pp0Ol05pj/+Yh77969dOrUCWdnZ3x9fRkyZAg5OTnm7YMHD6ZPnz58+umnBAcH4+vrS0xMjPla5WEymXjnnXcIDQ3F0dGRZs2asXTpUvP2wsJChg0bRnBwME5OTtSoUYOJEycCoJRi/PjxhIWF4ejoSEhICMOHDy/3ta+XTbfiNhqNjB8/nhkzZpCSkkJISAiDBw/m7bffvqGTnP8bO58wALyLU0EpsFIcQogboDD32o8xOILh4lepsRiMBaDTg/0lY/Vf6bwOruW+jJ2dHU888QTTp0/nrbfeMn8Hzp07F6PRyCOPPEJOTg4tW7Zk9OjReHh4sGjRIh5//HHq1KlD69atr3oNk8nEAw88QGBgIFu2bCEzM9OivrqEu7s706dPJyQkhL179/Lss8/i7u7Oa6+9xoABA9i3bx9Lly5l5UptYl5PT8/LzpGbm0u3bt1o27Yt27ZtIy0tjWeeeYZhw4ZZ/AhZs2YNwcHBrFmzhiNHjjBgwACaNWvGs88+W6737f/+7//47LPP+Oabb2jevDk//PAD999/P/v37yc8PJzPP/+chQsXMmfOHMLCwkhKSiIpKQmAX3/9lf/85z/Mnj2byMhIUlJS2L17d7muWxlsOkF/9NFHTJkyhR9//JHIyEi2b9/Ok08+iaen5039FXMpZ9/qADipAsg7Dy4+VolDCHEDfBBy7cc8NB0i+2p/H/wD5g6GGu3hyUWl+0xuDBfOXn7s+GtrbPrUU0/xySefsHbtWjp27Ahoj7f79euHp6cnnp6evPrqq+b9X3zxRZYtW8acOXPKlaBXrlzJwYMHWbZsGSEh2nvxwQcfXFZv/Pbbb5v/rlmzJq+++iqzZ8/mtddew9nZGTc3N+zs7AgKCrritWbNmkV+fj4//fQTrq7aD5Uvv/ySXr168dFHHxEYGAiAt7c3X375JQaDgYiICHr27MmqVavKnaA//fRTRo8ezcMPPwxoeWXNmjVMnjyZr776isTERMLDw2nfvj06nY4aNWqYj01MTCQoKIguXbpgb29PWFhYud7HymLTj7g3btxI79696dmzJzVr1uTBBx+ka9eubN261WoxeXt6clZpXa3IOmW1OIQQt5+IiAjatWvHDz/8AMCRI0f4+++/efrppwHtqeO7775L48aN8fHxwc3NjWXLlpGYmFiu88fFxVG9enVzcgZo27btZfv98ssvREdHExQUhJubG2+//Xa5r3HptZo2bWpOzgDR0dGYTCbi4+PN6yIjIzEYDObl4OBg0tLSynWNrKwsTp8+TXR0tMX66Oho4uLiAO0xemxsLPXr12f48OEsX77cvN9DDz1EXl4etWvX5tlnn2X+/PkUF9+86YZtugTdrl07pk6dyqFDh6hXrx67d+9m/fr1TJo0yWoxebvac1r54qvLxng+CUNQY6vFIoSoZG+evvZjDJc0eoropZ1D94+yz4i91xfXJZ5++mlefPFFvvrqK6ZNm0adOnW46667APjkk0/4v//7PyZPnkzjxo1xdXVlxIgRFBYWVtr1N23axMCBA5kwYQLdunXD09OT2bNn89lnn1XaNS5lb28574FOp8NkMlXa+Vu0aEFCQgJLlixh5cqV9O/fny5dujBv3jyqV69OfHw8K1euZMWKFbzwwgvmJxj/jOtGsOkE/frrr5OVlUVERAQGgwGj0cj777/PwIEDr3hMQUEBBQUF5uXs7OxKjcnbxYFY5UtjjpN35gRulXp2IYRVXUOdcJkMdqX10ZV53kv079+fl156iVmzZvHTTz8xdOhQc330hg0b6N27N4899hig1SkfOnSIhg0bluvcDRo0ICkpieTkZIKDtR4rmzdvtthn48aN1KhRg7feesu87sSJExb7ODg4YDQar3qt6dOnk5ubay5Fb9iwAb1eT/369csV79V4eHgQEhLChg0bzD9iSq5z6aNqDw8PBgwYwIABA3jwwQfp3r07586dw8fHB2dnZ3r16kWvXr2IiYkhIiKCvXv30qJFi0qJ8d/YdIKeM2cOM2fOZNasWURGRhIbG8uIESMICQlh0KBBZR4zceJEJkyYcMNisjfoOWvwB6DoXNINu44QQpTFzc2NAQMG8MYbb5CVlcXgwYPN28LDw5k3bx4bN27E29ubSZMmkZqaWu4E3aVLF+rVq8egQYP45JNPyMrKskjEJddITExk9uzZtGrVikWLFjF//nyLfWrWrElCQgKxsbGEhobi7u5+WfeqgQMHMm7cOAYNGsT48eNJT0/nxRdf5PHHHzfXP1eGUaNGMW7cOOrUqUOzZs2YNm0asbGxzJw5E4BJkyYRHBxM8+bN0ev1zJ07l6CgILy8vJg+fTpGo5E2bdrg4uLCjBkzcHZ2tqinvpFsug561KhRvP766zz88MM0btyYxx9/nJdfftncBL4sb7zxBpmZmebXgQMHKj2uTIdAzis38or+/ReiEELcCE8//TTnz5+nW7duFvXFb7/9Ni1atKBbt2507NiRoKAg+vTpU+7z6vV65s+fT15eHq1bt+aZZ57h/ffft9jn/vvv5+WXX2bYsGE0a9aMjRs3MmbMGIt9+vXrR/fu3bn77rvx9/cvs6uXi4sLy5Yt49y5c7Rq1YoHH3yQzp078+WXX17bm3EVw4cPZ+TIkbzyyis0btyYpUuXsnDhQsLDwwGtRfrHH39MVFQUrVq14vjx4yxevBi9Xo+Xlxfffvst0dHRNGnShJUrV/LHH3/g63tzJkrSKaXUTblSBfj6+vLee+8xdOhQ87qJEycybdo0Dh06VK5znDx5kurVq5OUlERoaGilxNXvvxvYkZjB14+1oHuj4Eo5pxDi5snPzychIYFatWrh5ORk7XBEFfFvn6uK5CKbfsTdq1cv3n//fcLCwoiMjGTXrl1MmjSJp556yqpxebtqj2rO5lZewwshhBDiUjadoL/44gvGjBnDCy+8QFpaGiEhITz33HOMHTvWqnH5ujoAcF4StBBCiBvEphO0u7s7kydPvupMKzebt4s9P9h/TOOtGdBqObhXXoMGIYQQN4FSYCwCvR3obbM5lk0naFvl6+ZILV0y/vmpcGo7RPS0dkhCCCH+jbEQ0Jd2g8tOgZyLkx7ZOWujQhblafs5e4EygaOH5ZCtN5kk6ArwdnXgw+JHqRYaxtj691o7HCGEuL0ok/ZCB/qLo4wppY2DbjJd7I/uULr/+ROQdw5cA+DihEe4eJcm6OI8y5EhCy9O2OFaXLq/FUiCrgBfVweWmVoRWexROlmGsbjsAQqEEDbLhjuxiLIUF0Buujauubo4mpiTlzZyW14GcMkIY/4NwP5iS2p7Fy1BX/oo284Jgppo58k7D/mZYOeojQyXn3H5hCflUJkjnIEk6ArxvrSRWPIeWDgMkndDYCOI7APthmv/o4UQNsne3h6dTkd6ejr+/v5Wmx1PXEHJD6eS/y+FF+DCeSgsY3KRnPOXLOi1xKqKISsdXP0vrnYBr3paaTs///Jz2HmAm0fpsv0ls2+Vtf9l4SoKCwtJT09Hr9fj4OBw1WPKQxJ0BZS04jbkpqB2LEKXfHH6sdR92mvvPOj/E/hXznB1QojKZTAYCA0N5eTJkxw/ftza4YgSSmmPl/OzwMW3tARcmFs6G5idk1Y3bOcIpmIozAaFNpyqwUFL6soOcnOAnCtd6YZwcXEhLCwMfSU1OpMEXQElJei0YheK9Q7Yd5kAEfdB4iZYNQHSD2pTzj23Dgw3fkB1IcS1c3NzIzw8nKKiImuHUvUUF0LqXsg9C3U6adV/uWcBBToDFOdrL4ODZR2vUvD7MDi5Be5+C+pdnMbzzBFIj4XwLhAYaY07uiqDwYCdnV2lPo2RBF0Brg4GHOz0FBQ7kHLHWKr7uGgb/OpCeFf47x2QdgA2fgEdRlo3WCHEFRkMBoupDEUl+d8jcHS19nfEfVod8N45Ze/rVQMGLwKv6tpyp1Fw/G9o0qe0BB3aSHvdZiRBV4BOpyPE04njZy9wJC2nNEGD1ie6+0SY/xys+QDOHoX2I8Av3GrxCiFEueRnwqkdkHUanDy1Blj5GXBoKZzYqHVHcvaCZo9Cc23GLAqyYc8cCL8HvMK0da2fg9T9WuOrg39ecgEdoLSGWPbO2rEZJ2DJaHh4pvZ4OiBCewlJ0BXVrq4fx88msvZQOndHBFhubDIA4hfDgd8hdob2AX3idwhpZpVYhRDiqlIPwI+94MKZq+9b5+7Sv4+sgkUjoeOb0HG0tq5eN3glHhLWwS+Pg6M7PPg9VG+jtZou6RqVkQhbvgFXP229Tp5mXEoSdAXdVc+fWVu0BH0ZnQ4e+hGStsCyt7TBTH7qDY//BtVa3vxghRDiSgpzIe5PWPamlpzdgyGggVaazs/SkmtwE4jopXVTysvQtoNWZ7xjutalyeOSiYNK6mFr3wWvxGl1zSXtcS5Nwl5h0M1ytixRShJ0BUXX9cNOryPhTC4nzuZSw/cfE7LrdBB2Bzw+H2b0gzOHtA++EEJYi7EYzsRrXZFKkmzhBZg/RPs7uKn2tM/Zu3zn0+ngiQX/vo+D679vF1ckCbqC3BztiKrpzeZj51h7KJ0n2l7hQ+jkoX2A0w+Cx8V5W00m+PlhbYjQ5o+VPu4RQoh/U5irjR1d1jgL509A/BLtyd35BC3Z+tXX6nPrdNL2ObwcZj8CvuHwwmatdbWbPzR+SCvNtnux/MlZ3HCSoK9Dx/oBbD52jqnrjhHo4US3yKCyd3RwtXy0Hfc7HF6mNbqI6KnVvwghRHGhVrotGZVwz1wt4YZ3hXpdYc8vsHICtB0G7kGAAhc/2P4DHFlhea7Tu7T/NnqwNEHXuRvcArVXxgnwraOt7/fdTbk9cW0kQV+HPs2q8d3fCZw8n8dz/9vB14+1oGP9ABbsOkV0XT/L1t2Xqt8Tun+o/RIuSc4mo9bYoqTPoBDi9qCUloR3TIf98yGsbelj4xMbYMc0rQFVva5aPfD++bDmvcvPo9NDWDuo2wm8a2oNtLJTtKq2EvbOWuMtGTntliCZ4DoEeTqx6pW7GL9wP/N3nWLahuNsOnqWHzedwNXBwPj7I3koqvrlB9o5wB1DLdcdXQ2zHtIGc2/YG84fh6IL0O97y8YXQohb14VzsP4/WrckZdJGxTIVQ/bp0n0i+5T+Xa+7lng7va0tu/hAs4FaQyuDvfbDPjMJQlrAXa+VlogBGvUrOwZJzrcMnario8WfPHmS6tWrk5SURGho6A25RnJmHtEfrsakwMGgp9BYOmD6H8Pa0zjU81+Ovmj3L6WtKC8V3hUenSP/qIS4FShV9r/VxM1ad6JDS7Uf3v9k7wKNHoDmT0C1FjICYRVUkVwkJehKEOzpTMf6Aaw+mEah0UTzMC98XBxYdTCNP/eeLl+CbjpA+wd6eDkcXqHVEa2fpC1v+korcev0kqiFuFkunNMaZXmGav/uCnK0RFucrzWkCmiglWhLJO+BWf3Boxo8MFUrzRZkw6/PwqElpfsFRMLdb2qPoYsLwFSkncupHN8T4rYiCbqSDGhVndUH0wB4sVNd8gpNrDqYxtJ9KbzePaJ847Ma7LVGYxE9tWV7Z1g5Dpa/pSXrwgvgU1tr0BHY8AbejRBVSEEO7P5Zm2yh4+vaurSDsOgVrQVzvx+0/r0mE5zeCSl7IOFviPtDS55OnloJN/eMtnwpFz8YsRccXLTRAo1FWo+NkpbQ9i5a9ZVOrz2ajnpSexwtP7RFOUiCriSdIgLoFhmIq4Mdd9cP4EKhEUc7PSfOXuBgSjYNgj2ufpJ/avei9jhs69TSmVzS9sMPF0fpcbhCIzTQ6rBdAy7fp+QRXNI2bQCV5o+Do1vZ5zCZLOdPFcKWFWTDvl+14SULsrVWzJknIfMUFOVqY0Jfuu+J9eBXr/QzfnonfNfZ8pw6w8UBOy5Oc+gVBm5BkJOijYJVXFD6b8zeGR75WSthl5Ss9Qa45x2odaf8qBbXTBJ0JbE36Pnm8SjzsqujHXfW82fFgVSW7EupWILWG7RHYe1fhpS9Wnetxa9BTqpl4p0/VJuird/3WgM0peC3IdrgKHU6a6MAFRfArhlaKcC/vvZlBFr3jDtfg6DGpePfZqfAnyO1xidD1mpfYAcXad06gppqrcwPr9Be7V4sHeReiPIoLtSGv93ytfZUyCtMayjlHqj9YDz+N6Ts0xpGlTR6yjyljWjlVMa/o4Js2PqtNjlN3rmyr+lTG1oOLl32rQMP/gD2l4xfUK0lBDbWPucBDaDxg+AfAWcOgzJq41J7hZWWfvOzIDvZ8jrVW19+7TueL+87I4QFSdA3UI9GQaw4kMpvO08Sc3cdHO0qOCCJvXPpP/zH55cm1xIHftdKCOeOal8suWe0JJt3HvbN016XOr0T0GmD3p85BL89A3e/XZqg134M8YvgoemlpYu4P2H3LG0eVr96Wukb4MACeOBbqBGtLet0MvCKNRmLYc9sOHsEQluBZ3VwC7jYZ/ZGXbNI+1Fod3GS+nPHtAZR7UdqSRfgXIL2uTqxHjKS0CbwvSh1b+nfO38q/bt6m9IE/d+2UJCpTeEa3FRbt+AF7fN75rA2oQOATx2tW5HBHoKaaI+dXfy0RHvp0yAXn8tbOet08Pzflz9+DrrCLEpOHmX/YBCikkiCvoG6Nwpi4pKDnDyfx8zNiTzVvtb1n9TOwbJfo1LQ4yPtUXhJvZebP7y4E5I2a30hz5/QEni97hDYCJJ3Q2iU9gh8xVht1KFLv8A7j4GsU9ooRCUa3KeVogsyLyZnndYYJusk/HS/NtausRCcfaDnZ1qDt0tlp2gN30q+/FL2av0+k3eDqz90eEV7LJ91GhrerzWguRabv4ZaHSo+V2zqAe2/lz6GPL1La9BTknhAS4Dxi7XW9p7VoSBLu7ecNG2kuKintOSQn6XNaBbeFVoMujlVBUdWwrK3IT3u8m0tB0OXCYACR8/SeBaPgthZWv3ovR9r6+KXavWojfppT0dKqjqK8rVHyHF/aP+vPIIhK1nbt/+PWvdApWDOIK0e19UP7hylnTNhnfYDr4SzD7R5DoKbaU9qDA5wbI32Y9MjVPuMt3nukhu4mNBLZks6vgFiZ5Zu9qmjdTNq9OD1jSMgdcPChkg3qxts1pZE3py/F28Xe9a+djceTrdw9wmTUfviPbVTexzoU1v7go9frCWqSz06VxtYoSBba4yz5xe4b7LWSGb/fJj3lNYPtEw6LUnf/ZZW+snP0MYxL3msv2IcpMVpc22X/FiZ+RCc2ASP/ao9bTh/XHuFNLMcuvD4Blj+ttaVpedn2rq1H8Oa96HJw/DAN9q6s0fhyyitDtKzmpZ4HN21pxJZp8oO2y3QchCI/2um/fh5fIHl7D/njkF2KnjX0O6rZH9jkbbNp/aVu9nsmaslzZDm2nCPWafhy9ZaSa4kLmdv7cdY8h7tka/5MezFqf56/xeaD9RW7ZoBv8dYzkS0eQosfV27d3tnrU61RjvtPbnSvff4uDShHlykVZ20Hwk1o0vXJW3V6mKDGms/yspKhiaTtr6sbQXZ2v8D0P5/HFqqVff41deeFsgAP8KGSTcrG9Q/KpTv1x/jaHou3647xitd61/9IFulN2iJIaR56boHvtESd0ai1mJ1yxRtIIbMpIvH2GulZL0dNH1EW1e7o5ZEarbXGu4cWqqVzDxCwaeWVgd54HftVWLQH9qXO2jz1R7/G+r30BK0ujjcYWG21oBOp9fqDEuu71MbctO1es6SHxJhbUvPHd4V1n6kxVgidZ/WejfvvJboL+Xip70H2cnaPm6BWsJxC7BMLK2e1upSL03Ovz4De+eWLnvXhFp3adc+uEhrfOTiqz2ezT2jlUJLRpUqyoPfngUUvHpYu55HiNbqf89s7Rytn4O7Rln+KEn4G/58Gc4e1pb3zilN0I36aTH4XDLAReP+Wuk0Za/WtgG0EjBo/49aDtJaImcna/EFN9PegxKX9kT4t3Vl+bcnDSXJGbT3uX6Pq59PiFuYlKBvgiV7kxk6cydujnasH303Xi4OVz/oVpaRqE3IXlL/mLJXSy6XNqApST4lCi9oJUK9QXvcvHK8Nl45gIM7PDRNmxAetC4ysTO1LjMlM+UUXoA5T5SOR2xw0JJGyQ+FS7V4Qivd+VxS5ZCVfPmIbUpp95KdoiX9/Eytm03tjlrJ8lrlnYdPwrUfCp7VtdJoyQ+JEjq95ZMFrxowYk9pjAuHafE8v770x0B2qlbn7F1D67NbFqW0ngC56dpECeUpbWYkaqV6kxGOrtLe68b9wd7p2u9diNtcRXKRzSfoU6dOMXr0aJYsWcKFCxeoW7cu06ZNIyoq6uoHYxsJ2mRS9PxiPXHJWcTcXYdR3SKYsfkEKw6kElXDmwejQgn2rMAXflVXmKsl+mt5dJl1cchEFz+t7jj9kFZP7hak/QBw9NDq6K0hJ12rDqjdUUumBTla4kvZqyXtwEZQ/16t7UBWsvYDw8EVarS96qmFELatyiXo8+fP07x5c+6++26GDh2Kv78/hw8fpk6dOtSpU+fqJ8A2EjTA8v0pDPnfDlwdDMx5vi19v9poHhLU392R32OiCfGSJC2EEFVRlauD/uijj6hevTrTpk0zr6tVqxJaQlvBPQ0DaRrqye6TmTz67RYKjSbqB7pTZDJxLD2XZ37cztzn2+LqaNP/S4QQQtwkNj1M1MKFC4mKiuKhhx4iICCA5s2b8+233/7rMQUFBWRlZZlf2dnZNynaf6fT6Xjj3gYAZOZpwwW+3iOCn55qjZ+bAweSsxjxSywpmfl8vz6BlMx8io0mJi6O48892mPbv+LTzH8LIYSo2my6uHbs2DGmTJnCyJEjefPNN9m2bRvDhw/HwcGBQYMGlXnMxIkTmTBhwk2OtHzuqO1LlwYBrIxLIyLInY71/dHpdEx9IoqHp25mxYFU1hxMo9ik+PtwOg+3qs43647h7qSNSjbkfzsoLDZhp9fTvdENHHhCCCGE1dl0HbSDgwNRUVFs3LjRvG748OFs27aNTZs2lXlMQUEBBQUF5uVTp07RsGFDq9dBl0jOzOOz5Yd4om0NmoR6mdf/HnuKl2bHmpft9Drah/vxV3w6oJW2P1xyEABfVweWvXwnfm6OV73ebztPEuTpRLs6flfdVwghxI1R5eqgg4ODadjQcoD5Bg0a8Ouvv17xGEdHRxwdSxNXVlbWFfe1hmBPZz59qOll63s3q4azvYHcwmK+WXuMgynZ5uQM8N3fx8x/n80t5INFcUwa0Oxfr7XvVCYj5+zGy8WeXWPuKd+MWkIIIWyCTddBR0dHEx8fb7Hu0KFD1KhRw0oR3VhdI4Po2zyUexsHX7btTE4hAAPbaEMd/r77NKcz8v71fOuPnAEg40IRp66yrxBCCNtSoQSdlJTEyZMnzctbt25lxIgRTJ06tdICA3j55ZfZvHkzH3zwAUeOHGHWrFlMnTqVmJiYSr2Orbk0QdcPdLfYNuTO2txR2wejSfHjxuP/ep6NR8+a/z6cmlOpMQohhLixKpSgH330UdasWQNASkoK99xzD1u3buWtt97inXfeqbTgWrVqxfz58/n5559p1KgR7777LpMnT2bgwIGVdg1bVDfAjSahngC82bMB9gbt0XSQhxNhPi4826E2AD9tOkH3yev4YLE2OYJSiswLRWTmFVFYbGJbQunUe/GpttGaXQghRPlUqA563759tG6tDds4Z84cGjVqxIYNG1i+fDnPP/88Y8eOrbQA77vvPu67776r71jFfPtEFInnLtCqpg9NQr3YceI8rWv5oNPpuLt+AHX8XTmansvBlGwOpmRTN8CNmVsS2Z2UAUDLGt7kFZUOI3lIErQQQtxSKpSgi4qKzA2xVq5cyf333w9AREQEycnJ/3aoKKdADycCPbQxjx9qGcrOxPM82FJr+afX6/hhcCv+PnyG3UkZzN1xktfm7bE4fseJ8wB4OtuTmVckCVoIIW4xFXrEHRkZyddff83ff//NihUr6N69OwCnT5/G19e3UgMU8HDrMI59cC931isdQ7qGryuP3VGDd/s0ooavNg2jj6sDK16+k68fa4lBrz0WH9CqOgBH0nIYPG0rXf+zluz8okqLLTu/iJyC4ko7nxBCCE2FEvRHH33EN998Q8eOHXnkkUdo2lTrNrRw4ULzo29Rua7URcrJ3sDXj7Wkf1QoM59pQ3igO90bBfHtEy15/I4aDO8cjqOdnvwiE3/Fp3MoNYeFu8s/Gtm53EJyr5CA8wqNdPvPOnp9sZ4i45XmdhZCCFERFXrE3bFjR86cOUNWVhbe3qXzzg4ZMgQXF5dKC06UT4NgDz5+0LJvdaeIQDpFaNM91g1wY//p0v7gc7YlMbCNZVe17PwiluxLAbRH6jqdjmPpOfT+agN6nY5vn4iidS0fi2N2JZ3ndGY+ALuTMoiqabldCCFExVWoBJ2Xl0dBQYE5OZ84cYLJkycTHx9PQEBApQYorl9JV60gDyfsDTp2n8wkLrk0Yf8Vn0abD1bx2rw9vDZvD4v2JmM0KV6Zu5vs/GIy84p47Pst/BWfZnHeHcfPm/9edyidsvwVn8aquNQbcFdCCFG1VShB9+7dm59++gmAjIwM2rRpw2effUafPn2YMmVKpQYorl+/lqHU8nPlw36N6dJAK1VP25AAaCXn1+bt4UKhES8XewAmLj7IhD/2sysxA3dHO+6u709hsYlX5uxmd1IGr87dzZK9yWw/cUmCPqwNilJYbOJ/m46z52QGadn5PP3jdp7+cTsbLw6aIoQQonwq9Ih7586d/Oc//wFg3rx5BAYGsmvXLn799VfGjh3L0KFDKzVIcX2i6/qx5tWOADgY9CzZl8Kc7Sfxc3MkJSuftOwCavm5suCFaHr83zpOZeTx06YTAIy7P5JeTYPp/eUGDqZk0/urDQAs2ZuM/pJ68T0nMzh+JpfRv+5hS8I5gj2dGNapLkaTNtT7qHl7WDqiA+5O9jf35oUQ4hZVoRL0hQsXcHfXHpsuX76cBx54AL1ezx133MGJEycqNUBRudrV9eONHhEA/Pevo/y28xQA7/ZuhKeLPW/11MY+93Kx578DW/Bgy1Ac7Qx81r+pecAUgNxCI9kFxbg4GKjt54pJQbfJ69hycXCU5Mx8Jq88bN7/VEYeg37YyrH00hHNlFJ8vPQg7/15ABues0UIIayiQiXounXrsmDBAvr27cuyZct4+eWXAUhLS8PDw6NSAxSV77m76uBop2f2tiScHQzc0zCQ9uHabFc9mwRTy68DIV5OeLk4mI+JDPFk6hNRxCVn4eFkz9sL9gHQPMyLeoHuHDuTS0Gxidp+rtT2d2VlXBrp2dqsYu/1acTExXHsTMyg02dr8XV14PG2NWga6sV//zoKQKeIANrVLZ1x62xOAb/tPMUjbcJwc7TpOV2EEOKGqNA339ixY3n00Ud5+eWX6dSpE23btgW00nTz5s0rNUBxYwyOrsXg6FplbmsYUvaPrLvrB3B3/QAKi018ufoIKVn5tKzhw8A2YWRcKKJVTR8eigrlYHI2K+O0BmXVvJwZ2CaMjvX9eXP+PtYdSudsbiGTVx4213kDzNySiK+bI/tPZ9K7WTVG/7qHlXFpZOQVMqpbROW/AUIIYeMqPB90SkoKycnJNG3aFL1ee1K+detWPDw8iIiwnS/UiszBKa5uVVwq369P4NOHmhLi5WyxTSlF98l/E5+azeB2NRl/f6R5W3Z+Ed/9ncD/rdIefzvbG8grMmKn12Fv0JNXZKRfi1B+3alNxtIw2IPFL3UwH280KX5Yn0CgpxP3Nw25CXcqhBDX76bOBx0UFERQUJB5VqvQ0FAZpOQ20rlBIJ0vtgj/J51Ox9heDflm3TGebm9ZSnd3suelzuEcTMli2f5UXulajyX7Uthx4jzFJm3s8JLkDHAgOYv07AL83bWhZX/emsj7FycHWXconcSzF9Dr4YfBrXBxuPrHOa/QyINfbyTA3ZEfBreSObKFEDarQo3ETCYT77zzDp6entSoUYMaNWrg5eXFu+++i8kkI0oJreX4T0+1prrP5QPX6PU6vnq0BX++2J6n29fimYtJvG1tXzrWLx3O1NdVqwNff0TrY302p4BPlpXODz5vx0m2Hj/H5mPnmL7xOEopLhT++7Cjfx9OZ//pLNbEp3M0Pfe671MIIW6UCpWg33rrLb7//ns+/PBDoqOjAVi/fj3jx48nPz+f999/v1KDFFWPnUFPo2ralJo9Ggfz16sdqe7jQnp2AY99v4WmoV4EeDgy5a+j/H3oDD0aBTP61z1k5hXRMNiDp9rX4ru/jxHm48LyA6l8s/YYa+PT2Zl4ntHdI3i6fa0yS8crLxk05a/4NOoGuF3Xfaw/fIb41GyebFcTvV5K40KIylOhOuiQkBC+/vpr8yxWJX7//XdeeOEFTp06VWkBXi+pg751bTx6hke/3YK7ox3BXk4cSs3B3qDjl+fa0iJMG8XOaFJ0n7yOw2k5Fsc+2iaM9/s0skjSJpOi9QerOJOjtS7vEK6V8uHKY51fSZHRxMdLD/Lt39qALz8MjjIPrSqEEP900+qgz507V2ZDsIiICM6dO1eRUwpxmagaPni52JNxoYjs1By8XOz5+rGW5uQMYNDreL1HBM/+tJ3a/m7c2ziYL1cfZtaWRGr7ufJMh9qcysjjyWlbCfNx4UxOAfYGHUVGxZZj53j8+60cSs3mhY518HVz5GxOAY+2qcHZ3AI+W34IHdAk1JNH29QwzxB2OiOPYbN2sjMxwxzHsn2pkqCFEJWqQgm6adOmfPnll3z++ecW67/88kuaNGlSKYEJ4WCnZ97zbdl2/DzFRhOdGwRe1mIctAZrG17vhJ+bI/YGPd4u9kz44wATlxykaXUvNh45y6HUHA6laqXsrg2DiE3K4FRGHusvDkE6/o8D5vNl5BVx/EwuC2K1Wb/m7jhJenYBjap58t+/jrLnZAYmBe5Odjzcqjrf/p3AqoOpbDl2lp82neCtng3KjFMIIa5FhRL0xx9/TM+ePVm5cqW5D/SmTZtISkpi8eLFlRqguL3VDXCnboD7VfcL9ixNiIPb1SQ2KYPfY0/z+arDnMstBMBOr6PYpOjROAhvV3tmbE7E3cmOp9vXYmHsaRSQcCaX79cncKFQa1H+cKvqzN6WxOerj1hcr2UNb/7TvxnBXk7M3pbEmZxCnvhhKwXFJvzdHS26lgHkFxmZuSWRTUfP8lbPBtTyc73Od0YIUdVVKEHfddddHDp0iK+++oqDBw8C8MADDzBkyBDee+89OnTocJUzCHHj6HQ6Xu1an99jT/P3xUk89DpYOqIDyZn5tK/rR7PqXhhNMLBNGI2qeTKiSz2MJsU9/1nLsYutu9vX9ePDfk1wtNPz48WxyZ9pX4sn29ei2iUl5E4RAfwee5qCYq0Hw4oDqYzr1dBcr73vVCbPz9jByfN5ADja6flqYIub9n4IIW5NFR6opCy7d++mRYsWGI3GyjrldZNGYrevx7/fYk7QrWp6M/f5dlc9Zu72JEbN2wPAT0+15s562kxeMzafICLI3WI40hKL9iQTM2sndnoder2OwmITi4a3x9FOz7L9qXyx+jD5RSb83Bw5k1OAnV7Hpjc64+/uyLpD6aw7lM4rXevj7GCo3DdACGEzbupAJULYukdbh5kTdNeGQeU6pk/zaqyMS8XV0Y4OF8cnd7DT81T7sodFBegaGciQO2vTNNSL+btOsTIulVfm7OZgSrZ5nzvr+fPFI8154oet7E7KYN6OkzzVviYj58RyJqcQf3dHnrurznXcrRCiqpEELaqsLg0DqeblTHpOAd0blS9B2xv0fPN41DVdx96g5817GwCQW1jMyrhUc3LuEO5H90ZBDIiqjp1Bz8DWYexOyuDnrYn4uztyJkerH5++8ThPta+FvaFCYwcJIaogSdCiyrI36Pl1aDuy84vKHNHsRugcEWBujDaqW31i7q5rsf2+psF8sCSOxHMXePO3veb1yZn5zNtxkvuaBMuc2UII4BrroB944IF/3Z6RkcHatWulDlrc1v6KTyO/yEj3RsFlbl99MJWnf9yOUlrL8odbV2fG5kQAHAx6xt3fkG6RQXy5+gi9mgbTsobPzQxfCHED3PA6aE9Pz6tuf+KJJ67llEJUOR3rB/zr9k4RgYzqVp+Pl8Zzf9MQXrmnPhuPnOXYmVwKjSbG/b6f79cncCw9l83HzrJ0xJ0VjmX+rpNM23Cc/w5sQaj3zXmKIISoHNeUoKdNm3aj4iiXDz/8kDfeeIOXXnqJyZMnWzUWIa7HCx3r0jkikBq+LjjZG1j9akeUUgybtYtFe5PNXb0OpmRzLD0HLxcHnOz15Zqx64tVhzmQnMVn/ZvyydJ4TmfmM3/nKV7sHH6jb0sIUYlumTrobdu28c0338hIZaLKqB9kOQCLTqdjYr/GHD+by5mcAnxcHYlLzuKL1UdYvj+FQA8nfh8W/a911PlFRv5v1WGKTQo3RztOZ+YDsOdU5g29FyFE5bslmozm5OQwcOBAvv32W7y9va9+gBC3KA8nexYOa8/60Z0Y3K4GAPN3nSK30MixM7lMuGRI0rLEJWdRbNKalczdUTqv9p6TGRb7KaVYczCNUxl5lXsDQohKc0uUoGNiYujZsyddunThvffe+9d9CwoKKCgoMC9nZ2f/y95C2B6DXocBHV0bBvHm/H0YL5aGLxQWM2/HSTrW9yfU24UhP20n2MuZjvX8ycovok0tH1Iulpj/KTWrgNSsfAI9nFBKMW7hfn7adIJG1Tz480UZ+U8IW2TzCXr27Nns3LmTbdu2lWv/iRMnMmHChBsclRA3nrerA/c0CGTp/hTe79uIQ6nZfLXmKKPn7cHT2Z607ALSsgvYnZQBwIzNJ4i+ONKZs72BvCIjrg4GAjycSDiTy+6kDO6q78+43/cze1sSAPtOZXEkLZv9p7PILTDyQItqONnLiGZC2IJKHeqzsiUlJREVFcWKFSvMdc8dO3akWbNmV2wk9s8S9KlTp2jYsKF0sxK3pAuFxSRn5lPH341io4nHvt/C5mPalK5hPi4MaleTA6ez2JJw1jzWN8C7fRrx08bj9G4WwvGzF5i34yQPtQzlUFoOu5My0OkgxNOZUxl5dAj3M4+4FuLpxHt9G8nUmUJUsop0s7LpBL1gwQL69u2LwVD6i95oNKLT6dDr9RQUFFhsK4v0gxZVSXp2AX2+2sD5C4X8MqQtjUO1ro/fr0/g3T9L66d3jrkHH1cHAP636Thjft9v3ubpbM9/BjQl40IRI+fsNq8vmScbYNjddXmlaz3zhB8ARUYTm4+dpXmYN26ONv/wTQibUuXG4u7cuTN79+61WPfkk08SERHB6NGjr5qchahq/N0dWfXKXVwoNJoTMMD9TUP4YHEcRpMizMfFYluTUC/z37X9XZk+uDVhvi5k5RfhYNBTaDTh6mBg2ct38t3fCUzfeJwv1xzB2cFgHgntwOksXpm7m7jkLB5tE8YHfRvftHsW4nZl0wna3d2dRo0aWaxzdXXF19f3svVC3C6c7A2X1RP7uztyZ7gfa+LTaRJqOaBQwxAP7qjtg4OdgckDmpmTt4eTPfdEBrJoTzIv3F2XUG8Xxt8fSW1/V8b+vp9Pl8fTMNiDFjW8eXjqJrLyiwHYeOTMzblRIW5zNp2ghRDl90rX+uQUFPNktOXMW/YGPbOHtC3zmA/6NObBFqHcVc/fvO6JtjU5mJLNrC2JjP51D0+3r0VWfjE1fF04cfYCx89e4ExOAX5ujhbnyi0o5v9WHaZv82o0CPao/BsU4jZj03XQlUHqoIW4dgXFRjp9upZTGXnmyT/e6R3J/zad4HBaDt8+EcU9DS0bkk356ygfLT1Iw2APFg1vb1F/LcTtriK56JYYqEQIcXM52pXWPxebFM72Bvo0r0aLMG2goB0nzl92zN+H0wE4kJzFrotdv8oyfUMCg37YyrncwsoPXIgqRBK0EKJMD7YMJdTbGYBeTYPxcLKnZQ0tQe9MPM/mY2cZ9/s+Hv9+C/tOZbL9eGnS/u+aI7z75wH+2H3a4pxfrTnC+D8OsPZQOr9c7IsthCib1EELIcrkYKfn04ea8v36BF7qUg+AFjW8ANiacI6Hp24273swZRuFRpN5gJSVcWnmc3QI98PLxYG525P4ZFm8+ZhFe08ztGMd83JqVj4vzNzJgKjq9G9V/SbcoRC2TUrQQogruqO2L98+EUU1L60kXdvPDU9nbbIOvQ4eaF4NO72O9GxtcKCeTYJpEeYFaEOWFhabmL/rFEfSchh7sS/2oLY1MOh17DuVxfEzueZrzdtxkh0nzvP+4jjyi2xnTnkhrEUStBCi3PR6Hc/fVYdm1b345bm2TBrQjIeiSku7HcL9+GFwK+a/0I6x9zUE4H+bTvD8jB3kFRmJruvLuF6RtKvjC8CivcnmYzcfOwtAZl7RZY/GhbgdSYIWQlyToR3rsCAmmlY1fQAY1qkuDnZ6HAx62tXRHmc3D/OmT/NqONnrOXYmlyNpOQS4O/Kf/s3Q63X0bBwMYE7EBcVGth0/Z77GjC2JFtf8c89ppvx1FJOpSnc6EcKCJGghxHWp5uXMvOfb8vOQNvi7l/aN9nS2p1eTEADqB7rz2wvtCPBwAqB7oyAc7PQcTMlmz8kMdidlkl9kwtPZHnuDjt1JGey7OIf10fQcXpody0dLD/LHHilZi9uHNBITQly3S4cTvdTb9zUkuq4fXRoGWozf7eXiQM/GwczfdYqZmxMJuVjH3SHcD6W0R98Ldp2iUTVPPl56EOPFkvNnyw/Ro1EwDnZSthBVnyRoIcQN4+lsT5/m1crcNrBNGPN3neL33aeo6esKQNs6vvi5ObJobzKL9ibTNTKIZftT0eu0cyWeu8Cj327G3qAnp6CYNrV8eKtnA9YeSuf4mVwGtatZoQFSEs9e4PjZXO68ZEQ1IaxNErQQwipa1vCmfqA78anZHEzJBiC6jh9Bnk64O9qRnJnP8zN2ADCgVXUiQzx5e8E+tl8ySMreU5m4ONox5a8jFBkVNfxcubt+wDXFYTIpnvhhC8fPXuCPYe3NM4QJYW2SoIUQVqHT6RjZtR5v/LaXRtU86R8VSk0/rSR9T2Qgv+08xbncQvzcHHitWwSezva4OdqRW1iMm6MdWxPOMXNLIp+vOmw+5+ytidecoDcePcvxsxcA2JV0XhK0sBmSoIUQVtMtMohukUGXre/VNITfdp4C4N3ejfC+OAPXpY/Lu0UGsfHoWRLO5OLuaEd2QTGr4tI4fiaXYpOJugHu5Yrhl+2lI5rFJWdfz+0IUamkpYUQwuZ0qOvHI62rM7xzOD0udsn6Jyd7A5P6N6VZdS++HNiCFmFeFJsUnT77iy6T1rGwHH2pMy4Usmx/inn5YEpWpd2DENdLStBCCJtjZ9Az8YEmV92veZg3C2KiAUjLymdnYgYlXaW/XH2Y5tW9mLruGI+3rUG9wMtL1H/sPk1hsQlfVwfO5hZyKCUbk0mh18tMXML6JEELIaqEfi1CyS8y4uFsz1vz93EoNYfeX23gXG4hR9NzmPXsHZcds/Ri6fnpDrWYvPIwuYVGTp7PI8zX5WaHL8Rl5BG3EKJK0Ot1PN62Jr2bVePhi5NtlExpufHoWYtxvwEyLxSx+Zg2etm9jYIJD3ADIE4ecwsbIQlaCFHlPNm+Fo52epzs9UQEaY+2Z/9jesvV8akYTYr6ge7U9HOl/sX9Dl6hoZjRpJi0PJ6v1hzhvMxlLW4CecQthKhyqnk588eL7bHT6ziclsNz/9vBrC0nOHE2F0c7PT6ujsQmaf2pu0YGAtAgyAM4RXxqFiaTYvD0beQXGvnfM61xtDOwbH8Kn68+AmjzWs8ecscVR1ATojJIghZCVEkljcKq+7gQ5OFESlY+S/alXLZfSTeviGBt/x0nzrPp2FnWHUoHYPbWJAa1q2nu9uVkr+dCoZEfN57gs/5eN+FOxO1KErQQokqzN+iZ/lQr1h8+g4OdnoIiE6cy8th2/BzhAW5EhngA0KqmD14u9qRmFTBmwT7z8V+tOcI9DQP5Kz4NgNe6RfDOnwfYcOQMSqkKDS0qRHlIghZCVHkRQR5EBHn86z5O9gYebBHKd+sTOHaxQZmzvYG07AIe/34LxSZFZIgHj7YJ48OlB0nJyufYmVzq+LvdjFsQtyFpJCaEEBc90ibM/HeQhxMfPNAIgKPpWsLu27waTvYGWoZ5A7DhyJmbH6S4bUiCFkKIi+r4u9G2ti8A9zcLoW/zUOY+35Z+LUK5p2Eg/S9234quq+1TVoJOPHuBxXuTOXA6i2Kj6eYFL6ocecQthBCX+KhfE37Znshzd9UBtLrpVjV9LPZpV9cPlh9i45GzLNh1ilMZeWw/fo7DaTmcPJ9n3q+GrwtLXurAvlNZrDiQwitd6+Nkb7ip9yNuXTZdgp44cSKtWrXC3d2dgIAA+vTpQ3x8vLXDEkJUYWG+LozqFoGHk/0V92lSzZNafq5kFxQz4pdYPlkWz5r4dE6ez8Og19Ew2AMHOz0nzl7g78NneG3ebr79O4Ffd568iXcibnU2naDXrl1LTEwMmzdvZsWKFRQVFdG1a1dyc3OvfrAQQtwgdgY9vzx3B8Purkt4gBudIwJ4p3cks4fcwa6x97D4pQ482lqrz57y11HzdJZ/HzpDZl4R369PIDOvyJq3IG4BOqWUsnYQ5ZWenk5AQABr167lzjvvLNcxJ0+epHr16iQlJREaGnqDIxRCCM36w2d47PstFuvcnezoFBHA77Gnebp9Lcbc15BiowmDXifdtaq4iuQimy5B/1NmZiYAPj4+V9lTCCGsq3UtH9wdLZv5ZOcX83usNg3m34fTOZiSRaPxyxj96x7+ray07lA6T/ywlbcX7GXHifM3NG5hO26ZBG0ymRgxYgTR0dE0atToivsVFBSQlZVlfmVnywTsQoibz8FOz531/AGw0+vMLb9LHErN4YtVR8gvMjFn+0nm7rhy/fTnqw6z7lA6MzYn8vDUTRxJk++128Etk6BjYmLYt28fs2fP/tf9Jk6ciKenp/nVsGHDmxShEEJY6tkkGICO9f25r0mIeb29QXucvWhvsnnd+IX7iU3KuOwcRpPiQLI2w1a9QDeKjIo3f9tHwplcks5duIHRC2u7JRL0sGHD+PPPP1mzZs1Vn92/8cYbZGZmml8HDhy4SVEKIYSlHo2CmPlMGz55sCkd6/vjbG+guo+zuQEZgIeTHW1r+3Kh0MiAbzaxdJ+WtFcfTOWH9QkknMnlQqERJ3s93z3RCmd7A1uPn+PuT/+i86S1JJ6VJF1V2XSCVkoxbNgw5s+fz+rVq6lVq9ZVj3F0dMTDw8P8cnd3vwmRCiHE5XQ6HdF1/fB2dSDY05nlL9/J/Beiuau+v3mfrpFBfDsoik4RARQUm3hpdixH0rIZOmMn7/x5gO/XJwDQMNiDMF8XRnevbz62sNjE6oOpl103v8jIB4vjeGr6NvIKjTf+RsUNYdMJOiYmhhkzZjBr1izc3d1JSUkhJSWFvLy8qx8shBA2prqPC35ujrSq6YNBrz3m7tkkGDdHO759IorG1TwpKDYx6IdtFBRro5DN3a7NYx0Z4gnA4OhabHi9Ey93qQfAhqNnLa6RkplP3/9uZOq6Y6w+mMa6w+k36/ZEJbPpBD1lyhQyMzPp2LEjwcHB5tcvv/xi7dCEEKLC3J3seeveBgxqW4MOdf0AMOh1DLmzNgCnMkoLIcUmrXV3o2qlk31U83Km48VS+OZjZ81DiiqlGP3rHuIu1lkDZdZri1uDTQ/1eQt10RZCiGvyVPvLq+x6NAoi1NuZk+fzCHB3JCu/iPwiLfmWlKBLNKrmiYeTHVn5xew7nUVkiAe/x55m7aF0HOz0DG5Xk6nrjrE7KYO45Cx+2ZbEsE518XNzJL/IiKOdXvpe2zibLkELIcTtxM6g55Wu2qPrl7qEc2e4Vkq2N+gID7Sc1tKg13HHxYk9Xvx5J/XfXsKrc3cDMOzuuvRtXg2APSczGbNgH9M3HufdPw+weG8yjcYt479/Hb1ZtyUqyKZL0EIIcbvp2zyUHo2CcbI34OJgYPmBVBoGe+Bod/kkG+3q+LL8QCpJ50ofibeu5cPzd9VBr9Pms84pKGb7xcFNFu4+zZqDaRSbFDM3n+CFjnWkFG3DJEELIYSNKZnxqnfTamRcKKJ1rbJHT7yvaQi/7TpFoIcTL3epR71AN+wMpQ9GG1fzZOvxc+ZlpSArvxiA05n57D2VSZNQL87lFrIw9hQDWoXh7CCzbdkKecQthBA2Sq/X8WR0rcvqn0v4uTmycFh7vn0iioYhHhbJGaBZmJf576Ed61wc8xsigrTup8v2pwDw2rw9jP/jAD9uOm5xfJHRxNsL9jJj84nKuylRblKCFkKIKqppqBcATvZ6Yu6uy53h/iilSM8p4KXZsSzbn8qAqDBWXexL/c9xvlfFpTJjcyL2Bh29moTg6XLlKThF5ZMELYQQVVSniADubRxE29q+uDna0baO1qgsK78Ie4OOI2k5vDpvNyUdZvaezLQ4fvFerYRdZFQs3pfMI63DMJoUv8eeYvfF7ltv3NvA/EheVC55xC2EEFWUs4OB/w5syeNta1qs93Cyp3czrZX31oTSOuqUrHxOZ+Txy7ZEEs7ksiqudJSy32NPATBvRxIj5+zmx00n+HHTCZbsS6bYaGJn4nlMptKusQlncvnfpuMYTdJdtqKkBC2EELehDx9ojKezPd+vTyAiyJ0io4mj6bmMnBPL5mPncLTTU1BswtvFnvMXitiScI7kzDxmb9NGNnN3siM7v5i9J7NIzszn46XxvN2zAc90qI1Sihdm7iQuOQsXBzv6tSzf/MfCkpSghRDiNmRn0DPmvoasHHkXPz97B02rewGw+ZhWoi4ZarRP82q0rumDUjD29/3sSszAoNfxQse6AOw/ncnquDQAluzTHonHXhwcBWDd4XSUUqRm5d/M26sSJEELIcRtrG6AG96uDjSpVtpS3MPJjoggd/Q6eKB5qHkI0hUHtEfed9cPMA81uv90FntOaXXXsUkZZOUXMXtrkvlcG46c4ceNx2nzwSpembObHSfO8+i3m5mzrXQfUTZ5xC2EEILGoaUJ+sGW1Xm9RwRncgoI8XKmMZ48d2dtvll3DID+UaHUDXDDwU5PTkGx+TijSbEqLpWFu08DoNPBmZxCPlkWD8CvO0/y686TABxOy+HBlqHo9TJQypVICVoIIQQNgz1xtjeg08HAO8JwsNMT4uVs3j6qW336tQilW2Qgd0cEYG/Qm/tTX2rc7/vJKzJSx9+VDheHKs0tNOLuZIfDJf2007MLiD2ZgcmkyC8yUnRxwg9RSkrQQgghcHYwMP3JVhQUm6jj73bZdjuDns/6N7VYFxniyZ6LXbOianiz/cR580hlb/RoQMKZXNYd0qa7fCq6Ft0bBZGSmc+8nSdZtCeZuduTePmXWE6cvYBOp/XbrhfoRnJmPn2bV+OBFrd34zJJ0EIIIQBoc3HyjfKKDCmdAnNYp7o8NX0bJgVPRtekS8NADqZkwWJwMOgZeEcYAe5ONAj2ICu/iEV7kvn5krpqpbQ67JLpMbcknKNVTR+q+7hUyr3diiRBCyGEqJDGFxuWOdnraVfHj9d7RJBw5gKv94gAICLIg08faoqfmwMB7k7m4zrWD8BOr6PYpDDodfwy5A6CvZxZG59OalY+aw+lE5uUwfuL4vj68ZZlXvvk+Qv8uSeZB5pXI8DDqcx9bnWSoIUQQlRIk1BPRnWrT01fVxzs9Ay5s85l+zxYRh9oT2d7OoT7sSY+naF31SGqpjYZyKNtwgDo0TiInp+vZ+n+FJbuSybU24Wp647xcKvqtKvrR7HRxDM/budgSjZfrz3K+F6R3N80pMo1ONMppar0MC8nT56kevXqJCUlERp6e9dnCCGErUjLzmfniQy6NgwsM7G+9+cBvlufgIOdHgeD1lrcwaDny0ebk5ZdwNsL9lnsHxniwWvdI7gz3A+dTofJpEjLLiDQw9E8pWaR0URmXhF+bo5XjMtoUnyyLJ7afq70b1W90u63IrlIStBCCCFuugB3J7o3Crri9td7RHDi3AVWHEilsNiEl4s9GReKGPK/HZRMYf12zwYUFJuY8tdR9p/OYtAPW2ld04c+zavxy/YkdidpPwBGdq1HenYBYxbs48S5CzzYIpRXu9UnsIxH42sPpfH12qMY9Dra1fUl1Nt6deBSghZCCGGT8ouMTPjjAI52ekZ1q897iw4wd/tJik2KiCB3/nixPfYGPedyC/nvmiP8tPkEhcXl667lbG9gyJ21GdqxjsVkH6Pm7mbuDq2v9pPRNRnXK7JS7qUiuUgStBBCiFvGhcJi9p/Ooq6/NgLapZIz85i9NYkVB1IJD3Sjf1R1vlh9mH2ntGFH728WQs/GwXy2PJ6diRkAdGkQwNePtcTOoKfIaCLqvZVk5hUBWhLf+Hqny65TEZKgyyAJWgghxKWUUvyxJ5lRc3dTUGwiIsgdpaC2vytL9qXg6+pAoIcTB5KzeLlLPV7qEn7d15Q6aCGEEOIqdDod9zcNwdnewPMzdnAwJRuA+FTtv10jA2lbx48PFsUR4HHlBmU3miRoIYQQt6V7GgYy65k2HE3PxU6v4+NlBzmXW0i/FqE0D/Ome2QQDnbWGxFbErQQQojbVpvavuYR1Ho0DuJMTiG1/FwBMFi5X7UkaCGEEAJwd7LH3cne2mGY3RKzWX311VfUrFkTJycn2rRpw9atW60dkhBCCHFD2XyC/uWXXxg5ciTjxo1j586dNG3alG7dupGWlmbt0IQQQogbxuYT9KRJk3j22Wd58sknadiwIV9//TUuLi788MMP1g5NCCGEuGFsOkEXFhayY8cOunTpYl6n1+vp0qULmzZtsmJkQgghxI1l043Ezpw5g9FoJDAw0GJ9YGAgBw8eLPOYgoICCgoKzMvZ2dk3NEYhhBDiRrDpBF0REydOZMKECZetT05OtkI0QgghRGkOMpnKN1Y42HiC9vPzw2AwkJqaarE+NTWVoKCyZ0F54403GDlypHl5x44ddOrUidatW9/QWIUQQoirSU1NJSwsrFz72nSCdnBwoGXLlqxatYo+ffoA2q+PVatWMWzYsDKPcXR0xNGxdGi2Dh06sHXrVgIDA9Hrr6/KPTs7m4YNG3LgwAHc3d2v61y3A3m/ro28X9dG3q9rI+/Xtans98tkMpGamkrz5s3LfYzNT5bxyy+/MGjQIL755htat27N5MmTmTNnDgcPHrysbvpGy8rKwtPTk8zMTDw8PG7qtW9F8n5dG3m/ro28X9dG3q9rYwvvl02XoAEGDBhAeno6Y8eOJSUlhWbNmrF06dKbnpyFEEKIm8nmEzTAsGHDrvhIWwghhKiKbLoftK1xdHRk3LhxFnXc4srk/bo28n5dG3m/ro28X9fGFt4vm6+DFkIIIW5HUoIWQgghbJAkaCGEEMIGSYIWQgghbJAk6HKSOanLb+LEibRq1Qp3d3cCAgLo06cP8fHx1g7rlvDhhx+i0+kYMWKEtUOxaadOneKxxx7D19cXZ2dnGjduzPbt260dlk0yGo2MGTOGWrVq4ezsTJ06dXj33XeR5keadevW0atXL0JCQtDpdCxYsMBiu1KKsWPHEhwcjLOzM126dOHw4cM3JTZJ0OUgc1Jfm7Vr1xITE8PmzZtZsWIFRUVFdO3aldzcXGuHZtO2bdvGN998Q5MmTawdik07f/480dHR2Nvbs2TJEg4cOMBnn32Gt7e3tUOzSR999BFTpkzhyy+/JC4ujo8++oiPP/6YL774wtqh2YTc3FyaNm3KV199Veb2jz/+mM8//5yvv/6aLVu24OrqSrdu3cjPz7/xwSlxVa1bt1YxMTHmZaPRqEJCQtTEiROtGNWtIy0tTQFq7dq11g7FZmVnZ6vw8HC1YsUKddddd6mXXnrJ2iHZrNGjR6v27dtbO4xbRs+ePdVTTz1lse6BBx5QAwcOtFJEtgtQ8+fPNy+bTCYVFBSkPvnkE/O6jIwM5ejoqH7++ecbHo+UoK9C5qS+fpmZmQD4+PhYORLbFRMTQ8+ePS0+Z6JsCxcuJCoqioceeoiAgACaN2/Ot99+a+2wbFa7du1YtWoVhw4dAmD37t2sX7+eHj16WDky25eQkEBKSorFv0tPT0/atGlzU77/b4mRxKypInNSi1Imk4kRI0YQHR1No0aNrB2OTZo9ezY7d+5k27Zt1g7llnDs2DGmTJnCyJEjefPNN9m2bRvDhw/HwcGBQYMGWTs8m/P666+TlZVFREQEBoMBo9HI+++/z8CBA60dms1LSUkBKPP7v2TbjSQJWtxQMTEx7Nu3j/Xr11s7FJuUlJTESy+9xIoVK3BycrJ2OLcEk8lEVFQUH3zwAQDNmzdn3759fP3115KgyzBnzhxmzpzJrFmziIyMJDY2lhEjRhASEiLvl42TR9xXUZE5qYVm2LBh/Pnnn6xZs4bQ0FBrh2OTduzYQVpaGi1atMDOzg47OzvWrl3L559/jp2dHUaj0doh2pzg4GAaNmxosa5BgwYkJiZaKSLbNmrUKF5//XUefvhhGjduzOOPP87LL7/MxIkTrR2azSv5jrfW978k6Ku4dE7qEiVzUrdt29aKkdkupRTDhg1j/vz5rF69mlq1alk7JJvVuXNn9u7dS2xsrPkVFRXFwIEDiY2NxWAwWDtEmxMdHX1Zt71Dhw5Ro0YNK0Vk2y5cuIBeb/lVbzAYMJlMVoro1lGrVi2CgoIsvv+zsrLYsmXLTfn+l0fc5TBy5EgGDRpEVFSUeU7q3NxcnnzySWuHZpNiYmKYNWsWv//+O+7u7ua6Gk9PT5ydna0cnW1xd3e/rG7e1dUVX19fqbO/gpdffpl27drxwQcf0L9/f7Zu3crUqVOZOnWqtUOzSb169eL9998nLCyMyMhIdu3axaRJk3jqqaesHZpNyMnJ4ciRI+blhIQEYmNj8fHxISwsjBEjRvDee+8RHh5OrVq1GDNmDCEhIfTp0+fGB3fD24lXEV988YUKCwtTDg4OqnXr1mrz5s3WDslmAWW+pk2bZu3QbgnSzerq/vjjD9WoUSPl6OioIiIi1NSpU60dks3KyspSL730kgoLC1NOTk6qdu3a6q233lIFBQXWDs0mrFmzpszvq0GDBimltK5WY8aMUYGBgcrR0VF17txZxcfH35TYZDYrIYQQwgZJHbQQQghhgyRBCyGEEDZIErQQQghhgyRBCyGEEDZIErQQQghhgyRBCyGEEDZIErQQQghhgyRBCyGEEDZIErQQotLodDoWLFhg7TCEqBIkQQtRRQwePBidTnfZq3v37tYOTQhRATJZhhBVSPfu3Zk2bZrFOkdHRytFI4S4HlKCFqIKcXR0JCgoyOLl7e0NaI+fp0yZQo8ePXB2dqZ27drMmzfP4vi9e/fSqVMnnJ2d8fX1ZciQIeTk5Fjs88MPPxAZGYmjoyPBwcEMGzbMYvuZM2fo27cvLi4uhIeHs3DhQvO28+fPM3DgQPz9/XF2diY8PPyyHxRCCI0kaCFuI2PGjKFfv37s3r2bgQMH8vDDDxMXFwdAbm4u3bp1w9vbm23btjF37lxWrlxpkYCnTJlCTEwMQ4YMYe/evSxcuJC6detaXGPChAn079+fPXv2cO+99zJw4EDOnTtnvv6BAwdYsmQJcXFxTJkyBT8/v5v3BghxK7kpc2YJIW64QYMGKYPBoFxdXS1e77//vlJKmwb0+eeftzimTZs2aujQoUoppaZOnaq8vb1VTk6OefuiRYuUXq9XKSkpSimlQkJC1FtvvXXFGAD19ttvm5dzcnIUoJYsWaKUUqpXr17qySefrJwbFqKKkzpoIaqQu+++mylTplis8/HxMf/dtm1bi21t27YlNjYWgLi4OJo2bYqrq6t5e3R0NCaTifj4eHQ6HadPn6Zz587/GkOTJk3Mf7u6uuLh4UFaWhoAQ4cOpV+/fuzcuZOuXbvSp08f2rVrV6F7FaKqkwQtRBXi6up62SPnyuLs7Fyu/ezt7S2WdTodJpMJgB49enDixAkWL17MihUr6Ny5MzExMXz66aeVHq8QtzqpgxbiNrJ58+bLlhs0aABAgwYN2L17N7m5uebtGzZsQK/XU79+fdzd3alZsyarVq26rhj8/f0ZNGgQM2bMYPLkyUydOvW6zidEVSUlaCGqkIKCAlJSUizW2dnZmRtizZ07l6ioKNq3b8/MmTPZunUr33//PQADBw5k3LhxDBo0iPHjx5Oens6LL77I448/TmBgIADjx4/n+eefJyAggB49epCdnc2GDRt48cUXyxXf2LFjadmyJZGRkRQUFPDnn3+afyAIISxJghaiClm6dCnBwcEW6+rXr8/BgwcBrYX17NmzeeGFFwgODubnn3+mYcOGALi4uLBs2TJeeuklWrVqhYuLC/369WPSpEnmcw0aNIj8/Hz+85//8Oqrr+Ln58eDDz5Y7vgcHBx44403OH78OM7OznTo0IHZs2dXwp0LUfXolFLK2kEIIW48nU7H/Pnz6dOnj7VDEUKUg9RBCyGEEDZIErQQQghhg6QOWojbhNRmCXFrkRK0EEIIYYMkQQshhBA2SBK0EEIIYYMkQQshhBA2SBK0EEIIYYMkQQshhBA2SBK0EEIIYYMkQQshhBA2SBK0EEIIYYP+H8s8tp3KrUfqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.5 Decoding strategies to control randomness"
      ],
      "metadata": {
        "id": "6cjnH_zmmOxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx_eG12dmLQJ",
        "outputId": "9a007564-2051-45ee-caf2-26712e3f0538"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_size\"]\n",
        "\n",
        ")\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2NqVCIkmi_l",
        "outputId": "a6226c10-5225-4491-84a8-714c0e9a598c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you funked the _real.\n",
            "\n",
            "â€œSo you rascal?â€\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.1 Temperature scaling\n"
      ],
      "metadata": {
        "id": "T36emEXLnPOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Temperature scaling is a technique that adds a probabilistic selection process to the next-token generatin task.\n",
        "* In `generate_text` function, we always sampled tokens with the highest probability as the next new token using `torch.argmax`, also known as `greedy decoding`.\n",
        "* To generate text with more variety, we can replace `argmax` with a function that samples from a probability distribution i.e here, the probability scores the LLM generates for each vocabulary entry at each token generation step.\n"
      ],
      "metadata": {
        "id": "RGbypK-7nSlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    'closer':0,\n",
        "    \"every\":1,\n",
        "    'effort':2,\n",
        "    \"forward\":3,\n",
        "    \"inches\":4,\n",
        "    \"moves\":5,\n",
        "    \"pizza\":6,\n",
        "    \"toward\":7,\n",
        "    \"you\":8\n",
        "}\n",
        "inverse_vocab = {v:k for k,v in vocab.items()}"
      ],
      "metadata": {
        "id": "RZlWhkc4okMa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_tokens_logits = torch.tensor(\n",
        "     [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")"
      ],
      "metadata": {
        "id": "tAIukOHspHYb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = torch.softmax(next_tokens_logits,dim=0)\n",
        "next_token_id = torch.argmax(probs).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zh4kj-DpUgK",
        "outputId": "b5f06d08-b4e7-4f6d-df29-6c5b5378b379"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Since the largest logit value and, correspondingly, the largest softmax probabilitity score are in the fourth postion, the generated word is `forward`.\n",
        "* To implement a probabilistic sampling process, we can now replace `argmax` with the `multinomial` function in pytorch."
      ],
      "metadata": {
        "id": "B2egJjM4pwrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probs,num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k0Zjx3JqQMa",
        "outputId": "6043ecaf-2834-495b-d567-7aa044c9793a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The `multinomial` function smaples the next token proportional to its probability score.\n",
        "* In other words \"forward\" is still the most likely token and will be selected by the `multinomial` most of the time but not all the time."
      ],
      "metadata": {
        "id": "_hCJqySFqfkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##implementing a function that repeats temp sampling 1000 times\n",
        "def print_sampled_tokens(probs):\n",
        "  torch.manual_seed(123)\n",
        "  sample = [torch.multinomial(probs,num_samples=1).item() for i in range(1_000)]\n",
        "  sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "  for i, freq in enumerate(sampled_ids):\n",
        "    print(f\"{freq} x{inverse_vocab[i]}\")\n",
        "print_sampled_tokens(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ot67LNq1cB",
        "outputId": "85725361-fa15-4bfc-8443-ba9a0913c6c7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 xcloser\n",
            "0 xevery\n",
            "0 xeffort\n",
            "582 xforward\n",
            "2 xinches\n",
            "0 xmoves\n",
            "0 xpizza\n",
            "343 xtoward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here we see that \"forward\" has been sampled 582 times.\n",
        "* We can further control the distribution and selection process via a concept called `temperature scaling`.\n"
      ],
      "metadata": {
        "id": "1AU5E-yhsCDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits,temperature):\n",
        "  scaled_logits = logits / temperature\n",
        "  return torch.softmax(scaled_logits,dim=0)"
      ],
      "metadata": {
        "id": "oFZOxkjBsdEW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Temperature greater than 1 result in more uniformity distributed token probabilities, and temperature smaller than 1 will result in more confident distributions.\n"
      ],
      "metadata": {
        "id": "gnb55FgosuQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [1,0.1,0.5]\n",
        "scaled_probs = [softmax_with_temperature(next_tokens_logits,T) for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig,ax = plt.subplots(figsize=(5,3))\n",
        "for i,T in enumerate(temperatures):\n",
        "  rects = ax.bar(x+i * bar_width,scaled_probs[i],bar_width,label=f'Temperature={'T'}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(),rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "EmPblKjOtRCr",
        "outputId": "31fe793f-c9fe-479d-849b-1d660b6626cf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A temperature of 1 divides the logits by 1 before passing them to the `softmax` function to compute the probability scores.\n",
        "* For example,for the temperature setting 1, the token corresponding to `forward` would be selected about 60% of the time."
      ],
      "metadata": {
        "id": "9XxcRuRtu2I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.2 Top-k sampling"
      ],
      "metadata": {
        "id": "TX4eVynUvg1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In Top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens and exclude all other tokens from the selection process masking their probability scores."
      ],
      "metadata": {
        "id": "-wv0De6cvttQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits,top_pos = torch.topk(next_tokens_logits,top_k)\n",
        "print(\"Top logits:\",top_logits)\n",
        "print(\"Top positions:\",top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSG6YHCIwGjA",
        "outputId": "6a9e3772-81db-4325-b833-14d29094712d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can also apply, Pytorch's `where` function to set the logit values of tokens that are below the lowest logit value within our top-three selection to negative infinity (-inf).\n"
      ],
      "metadata": {
        "id": "GKjyzR4lwcOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_tokens_logits < top_logits[-1],\n",
        "    input=torch.tensor(float('-inf')),\n",
        "    other=next_tokens_logits\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D_XPJ6Sw53a",
        "outputId": "140d24e4-d6f7-4053-827d-a027554bb063"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probs = torch.softmax(new_logits,dim=0)\n",
        "print(topk_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB-vFzjCxalV",
        "outputId": "b4f156ad-6661-4e6d-cf87-5a84339afde3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.3 Modifying thext generation functon with more diversity"
      ],
      "metadata": {
        "id": "hjELxl4SxmBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:,-1,:]\n",
        "    if top_k is not None:\n",
        "      top_logits, _ = torch.topk(logits,top_k)\n",
        "      min_val = top_logits[:,-1]\n",
        "      logits = torch.where(\n",
        "          logits < min_val,\n",
        "          torch.tensor(float('-inf')).to(logits.device),\n",
        "          logits\n",
        "      )\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits,dim=-1)\n",
        "      idx_next = torch.multinomial(probs,num_samples=1)\n",
        "    else:\n",
        "      idx_next =torch.argmax(logits,dim=-1,keepdim=True)\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "    idx = torch.cat((idx,idx_next),dim=1)\n",
        "  return idx\n",
        ""
      ],
      "metadata": {
        "id": "AAwaSYiQxujq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"I am a sick man \",tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_size\"],\n",
        "    top_k=50,\n",
        "    temperature=2.0\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB8qVwmZzgE8",
        "outputId": "c395fc23-acef-4b56-ca20-0f2228c61919"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " I am a sick man as among anyone cameous. You may be corpulent or made us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.4 Loading and saving weights in Pytorch"
      ],
      "metadata": {
        "id": "YIBWUkZP0ww0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model.pth\")"
      ],
      "metadata": {
        "id": "yDFQ-YJj04uC"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"model.pth\",map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3IglhWq1A7m",
        "outputId": "08068bbc-7251-43fb-c7bb-aae9a6b8deb9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving model and optimizer\n",
        "torch.save({\n",
        "    \"model_state_dict\":model.state_dict(),\n",
        "    \"optimizer_state_dict\":optimizer.state_dict(),\n",
        "},\"model_and_optimizer.pth\")"
      ],
      "metadata": {
        "id": "lMccX-gc1X7M"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#restoring model and optimizer\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=5e-4,weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrS53JKs1xxF",
        "outputId": "1088d287-fb87-4e1c-ec47-481bae5cd8ce"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.5 Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "wKPN7XVx2y94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/\"\n",
        "    \"LLMs-from-scratch/main/ch05/\"\n",
        "    \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaNwkvik3F5_",
        "outputId": "70a1f6a0-b135-4652-8e2c-f1c42828258c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7a9aac279250>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size='124M',models_dir='gpt2'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwTPZqdx3JYh",
        "outputId": "b4778008-f9b1-45c1-c043-8b44fed2d1f3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 226kiB/s]\n",
            "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:01<00:00, 634kiB/s]\n",
            "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 274kiB/s]\n",
            "model.ckpt.data-00000-of-00001:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184M/498M [02:14<03:48, 1.37MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [00:28<00:00, 17.3MiB/s]\n",
            "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 2.24MiB/s]\n",
            "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:01<00:00, 326kiB/s]\n",
            "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:01<00:00, 368kiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##inspecting contents of settings and params\n",
        "print(\"Settings:\",settings)\n",
        "print(\"Parameter dictionary keys:\",params.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeFP-VKb4KAC",
        "outputId": "888b421a-53be-463d-f221-35ae0f19f46a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Settings` stores the LLM architecture settings similar to the manually defined `GPT_CONFIG_124M` settings.\n",
        "* The params contain the actual weight tensors."
      ],
      "metadata": {
        "id": "ztTjmuuR4fdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(params['wte'])\n",
        "print(\"Token embedding weight tensor dimensions:\",params['wte'].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQs88d6V47FZ",
        "outputId": "f1a7eb7d-fd3f-40b2-a1e7-e3fd6963cbe3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##transferring GPT2 weights from setting and params dictionary into our defined GPTModel instance\n",
        "# a dictionary showing the difference of GPT Model sizes\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "ZlDnA1mT5RB6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-small (124M)\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n"
      ],
      "metadata": {
        "id": "LS7Het7v5vbz"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##updating tokens length from 256 to 1024\n",
        "NEW_CONFIG.update({'context_size':1024})"
      ],
      "metadata": {
        "id": "ymcH8yTP5-Qx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##adding bias vector because  they were used in gpt2 computation of query,key and value vectors\n",
        "NEW_CONFIG.update({\"qkv_bias\":True})"
      ],
      "metadata": {
        "id": "v24WOvXf6SNy"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHBWucCw6kZc",
        "outputId": "7569c917-a397-44a2-9383-667230212afc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##overriding random weights with weights we loaded into the params dictionary\n",
        "# function that checks whether two tensors have similar dimensions or shape and returns right tensor as trainable Pytorch parameters\n",
        "def assign(left,right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(f\"Shape mismatch. Left: {left.shape},\" f\"Right: {right.shape}\")\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "AE_8d5b66t-6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining load_weight_into_gpt function that loads the weights from params dictionary into a GPTModel instance gpt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt,params):\n",
        "  gpt.pos_emb.weight = assign(\n",
        "      gpt.pos_emb.weight,\n",
        "      params['wpe']\n",
        "  )\n",
        "  gpt.tok_emb.weight = assign(\n",
        "      gpt.tok_emb.weight,\n",
        "      params['wte']\n",
        "  )\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    q_w, k_w, v_w = np.split(\n",
        "    (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.w_query.weight = assign(\n",
        "        gpt.trf_blocks[b].att.w_query.weight, q_w.T\n",
        "    )\n",
        "    gpt.trf_blocks[b].att.w_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.w_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.w_value.weight = assign(\n",
        "           gpt.trf_blocks[b].att.w_value.weight, v_w.T)\n",
        "    q_b, k_b, v_b = np.split(\n",
        "         (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.w_query.bias = assign(\n",
        "         gpt.trf_blocks[b].att.w_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.w_key.bias = assign(\n",
        "          gpt.trf_blocks[b].att.w_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.w_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.w_value.bias, v_b)\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "           gpt.trf_blocks[b].att.out_proj.weight,\n",
        "           params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "        gpt.trf_blocks[b].att.out_proj.bias,\n",
        "          params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ffn.layers[0].weight = assign(\n",
        "           gpt.trf_blocks[b].ffn.layers[0].weight,\n",
        "           params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ffn.layers[0].bias = assign(\n",
        "              gpt.trf_blocks[b].ffn.layers[0].bias,\n",
        "              params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ffn.layers[2].weight = assign(\n",
        "             gpt.trf_blocks[b].ffn.layers[2].weight,\n",
        "             params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ffn.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ffn.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "           gpt.trf_blocks[b].norm1.scale,\n",
        "           params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "             gpt.trf_blocks[b].norm1.shift,\n",
        "             params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm2.scale = assign(\n",
        "         gpt.trf_blocks[b].norm2.scale,\n",
        "         params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm2.shift = assign(\n",
        "    gpt.trf_blocks[b].norm2.shift,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "DHY4LApQ62rx"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt,params)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijnBn-JQ-iPp",
        "outputId": "33715400-e6b4-4ebc-a414-e6893153f651"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"I am a sick\",tokenizer).to(device),\n",
        "    max_new_tokens=30,\n",
        "    context_size=NEW_CONFIG[\"context_size\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIFUqdiE_TdG",
        "outputId": "4a78bae7-5a97-45f9-da1b-f0afbfcac13c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " I am a sick man as the King can confirm that I was put within my office of having an election which I would vote to deny him. I told him by telling\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNLMEVc8YrYhC7nITAVGazU"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}